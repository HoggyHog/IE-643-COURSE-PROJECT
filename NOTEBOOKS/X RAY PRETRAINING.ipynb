{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":861496,"sourceType":"datasetVersion","datasetId":457093},{"sourceId":7048965,"sourceType":"datasetVersion","datasetId":4056467},{"sourceId":7049140,"sourceType":"datasetVersion","datasetId":4056594},{"sourceId":7061299,"sourceType":"datasetVersion","datasetId":4065185}],"dockerImageVersionId":30587,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**INSTALLING THE REQUIRED DEPENDENCIES**","metadata":{}},{"cell_type":"code","source":"!pip install lightly -q","metadata":{"execution":{"iopub.status.busy":"2023-11-27T02:13:06.988311Z","iopub.execute_input":"2023-11-27T02:13:06.988926Z","iopub.status.idle":"2023-11-27T02:13:28.566448Z","shell.execute_reply.started":"2023-11-27T02:13:06.988889Z","shell.execute_reply":"2023-11-27T02:13:28.565180Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"**IMPORTING THE REQUIRED DEPENDENCIES**","metadata":{}},{"cell_type":"code","source":"#dependencies for file management and data visualisation\nimport os\nimport shutil\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport nibabel as nib\nimport re\nfrom tqdm import tqdm\nimport pandas as pd\nimport gc\nimport psutil\nfrom matplotlib.animation import FuncAnimation\nimport seaborn as sns\nfrom IPython.display import HTML\nimport cv2\n\n#pretraining dependencies\nfrom lightly.data import LightlyDataset\n\n#pretraining of SIMCLR MODEL\nfrom lightly.transforms.simclr_transform import SimCLRTransform\nfrom lightly.loss import NTXentLoss\nfrom lightly.models.modules.heads import SimCLRProjectionHead\n\n#pretraining of BarlowTwins MODEL\nfrom lightly.loss import BarlowTwinsLoss\nfrom lightly.models.modules import BarlowTwinsProjectionHead\nfrom lightly.transforms.byol_transform import (\n    BYOLTransform,\n    BYOLView1Transform,\n    BYOLView2Transform,\n)\n\n#pretraining on SWaV MODEL\nfrom lightly.loss import SwaVLoss\nfrom lightly.models.modules import SwaVProjectionHead, SwaVPrototypes\nfrom lightly.transforms.swav_transform import SwaVTransform\n\n\n#fine-tuning the models\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n\nimport torch.optim as optim\nfrom torch.utils.data import TensorDataset, DataLoader , random_split\nimport pytorch_lightning as pl\nimport torchvision\nfrom torchvision import transforms\nfrom pytorch_lightning import seed_everything\n\n#evaluating the models\nfrom sklearn.metrics import log_loss\n\nseed_value = 50\n\ntorch.manual_seed(seed_value)\n\nif torch.cuda.is_available():\n    torch.cuda.manual_seed_all(seed_value)\n\nseed_everything(42)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-11-27T02:13:28.568355Z","iopub.execute_input":"2023-11-27T02:13:28.568698Z","iopub.status.idle":"2023-11-27T02:13:38.882907Z","shell.execute_reply.started":"2023-11-27T02:13:28.568657Z","shell.execute_reply":"2023-11-27T02:13:38.881796Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"42"},"metadata":{}}]},{"cell_type":"markdown","source":"**LOADING IN THE IMAGES FOR THE PRETRAINING**","metadata":{}},{"cell_type":"code","source":"final_loc='./pretraining_images'\nc=0","metadata":{"execution":{"iopub.status.busy":"2023-11-26T17:38:49.553945Z","iopub.execute_input":"2023-11-26T17:38:49.554492Z","iopub.status.idle":"2023-11-26T17:38:49.558515Z","shell.execute_reply.started":"2023-11-26T17:38:49.554465Z","shell.execute_reply":"2023-11-26T17:38:49.557555Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"dir_1= '/kaggle/input/ct-chest-scans/images'\n\nos.makedirs(final_loc,exist_ok=True)\n\nfor file in os.listdir(dir_1):\n    c+=1\n    file_path=os.path.join(dir_1,file)\n    ext=file[-4:]\n    if(ext=='jpeg'):\n        ext='.jpeg'\n    new_filename=str(c)+ext\n    final_path=os.path.join(final_loc,new_filename)\n    \n    shutil.copy(file_path, final_path)\n    ","metadata":{"execution":{"iopub.status.busy":"2023-11-26T17:38:49.561504Z","iopub.execute_input":"2023-11-26T17:38:49.562127Z","iopub.status.idle":"2023-11-26T17:39:28.321660Z","shell.execute_reply.started":"2023-11-26T17:38:49.562102Z","shell.execute_reply":"2023-11-26T17:39:28.320803Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"dir_2= '/kaggle/input/xray-of-chest-2/images'\n\nos.makedirs(final_loc,exist_ok=True)\n\nfor file in os.listdir(dir_2):\n    c+=1\n    file_path=os.path.join(dir_2,file)\n    ext=file[-4:]\n    if(ext=='jpeg'):\n        ext='.jpeg'\n    new_filename=str(c)+ext\n    final_path=os.path.join(final_loc,new_filename)\n    \n    shutil.copy(file_path, final_path)","metadata":{"execution":{"iopub.status.busy":"2023-11-26T17:39:28.322740Z","iopub.execute_input":"2023-11-26T17:39:28.323024Z","iopub.status.idle":"2023-11-26T17:40:44.501673Z","shell.execute_reply.started":"2023-11-26T17:39:28.323000Z","shell.execute_reply":"2023-11-26T17:40:44.500307Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"counter=0\nfor i in os.listdir(final_loc):\n    counter+=1\nprint(c,counter)","metadata":{"execution":{"iopub.status.busy":"2023-11-26T17:40:44.503073Z","iopub.execute_input":"2023-11-26T17:40:44.503484Z","iopub.status.idle":"2023-11-26T17:40:44.519759Z","shell.execute_reply.started":"2023-11-26T17:40:44.503447Z","shell.execute_reply":"2023-11-26T17:40:44.518976Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"14999 14999\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**DEFINING THE SIMCLR PRETRAINING MODEL**","metadata":{}},{"cell_type":"code","source":"input_size=32\nSC_Imagenet_transform = SimCLRTransform(input_size=input_size)\n\n# Create a dataset from your image folder.\nSC_Imagenet_dataset = LightlyDataset(\n    input_dir=final_loc,\n    transform=SC_Imagenet_transform,\n)\n\n# Build a PyTorch dataloader.\nSC_Imagenet_dataloader = torch.utils.data.DataLoader(\n    SC_Imagenet_dataset,                # Pass the dataset to the dataloader.\n    batch_size=16,         # A large batch size helps with learning.\n    shuffle=True,           # Shuffling is important!\n    num_workers=4\n)","metadata":{"execution":{"iopub.status.busy":"2023-11-26T17:40:44.520732Z","iopub.execute_input":"2023-11-26T17:40:44.521021Z","iopub.status.idle":"2023-11-26T17:40:44.603347Z","shell.execute_reply.started":"2023-11-26T17:40:44.520997Z","shell.execute_reply":"2023-11-26T17:40:44.602648Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"max_epochs=15\n\nclass SimCLR(pl.LightningModule):\n    def __init__(self):\n        super().__init__()\n        resnet = torchvision.models.resnet18()\n        self.backbone = nn.Sequential(*list(resnet.children())[:-1])\n\n        \n        self.projection_head = SimCLRProjectionHead(512,512,2048)\n        #1st parameter -> input size (from the last layer of the resnet backbone)\n        #2nd parameter -> hidden size\n        #3rd parameter -> output size\n\n        self.criterion = NTXentLoss()\n\n    def forward(self, x):\n        h = self.backbone(x).flatten(start_dim=1)\n        z = self.projection_head(h)\n        return z\n\n    def training_step(self, batch, batch_idx):\n        (x0, x1), _, _ = batch\n        z0 = self.forward(x0)\n        z1 = self.forward(x1)\n        loss = self.criterion(z0, z1)\n        return loss\n\n    def configure_optimizers(self):\n        optim = torch.optim.SGD(\n            self.parameters(), lr=6e-2, momentum=0.9, weight_decay=5e-4\n        )\n        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optim, max_epochs)\n        return [optim],[scheduler]\n    \ntorch.cuda.empty_cache()\nSimCLR_ImagenetPT_model = SimCLR()\ntrainer = pl.Trainer(max_epochs=max_epochs, devices=1, accelerator=\"gpu\")\ntrainer.fit(SimCLR_ImagenetPT_model, SC_Imagenet_dataloader)","metadata":{"execution":{"iopub.status.busy":"2023-11-26T17:40:44.604260Z","iopub.execute_input":"2023-11-26T17:40:44.604542Z","iopub.status.idle":"2023-11-26T18:15:25.136438Z","shell.execute_reply.started":"2023-11-26T17:40:44.604512Z","shell.execute_reply":"2023-11-26T18:15:25.135468Z"},"trusted":true},"execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":"Training: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"62438e002562467c981acee05b4126fc"}},"metadata":{}}]},{"cell_type":"markdown","source":"**DEFINING THE BARLOW TWINS PRETRAINING MODEL**","metadata":{}},{"cell_type":"code","source":"BT_Imagenet_transform = BYOLTransform(\n    view_1_transform=BYOLView1Transform(input_size=32, gaussian_blur=0.0),\n    view_2_transform=BYOLView2Transform(input_size=32, gaussian_blur=0.0),\n)\n\nBT_Imagenet_dataset = LightlyDataset(\n    input_dir=final_loc,\n    transform=BT_Imagenet_transform,\n)\n\nBT_Imagenet_dataloader = torch.utils.data.DataLoader(\n    BT_Imagenet_dataset,   \n    batch_size=16,         \n    shuffle=True,           \n    num_workers=4\n)","metadata":{"execution":{"iopub.status.busy":"2023-11-26T18:15:25.138199Z","iopub.execute_input":"2023-11-26T18:15:25.138584Z","iopub.status.idle":"2023-11-26T18:15:25.225128Z","shell.execute_reply.started":"2023-11-26T18:15:25.138547Z","shell.execute_reply":"2023-11-26T18:15:25.224102Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"max_epochs=15\n\nclass BarlowTwins(pl.LightningModule):\n    def __init__(self):\n        super().__init__()\n        resnet = torchvision.models.resnet18()\n        self.backbone = nn.Sequential(*list(resnet.children())[:-1])\n        self.projection_head = BarlowTwinsProjectionHead(512, 2048, 2048)\n        self.criterion = BarlowTwinsLoss()\n\n    def forward(self, x):\n        x = self.backbone(x).flatten(start_dim=1)\n        z = self.projection_head(x)\n        return z\n\n    def training_step(self, batch, batch_index):\n        (x0, x1) = batch[0]\n        z0 = self.forward(x0)\n        z1 = self.forward(x1)\n        loss = self.criterion(z0, z1)\n        return loss\n\n    def configure_optimizers(self):\n        optim = torch.optim.SGD(self.parameters(), lr=0.06)\n        return optim\n        \ntorch.cuda.empty_cache()\nBT_ImagenetPT_model = BarlowTwins()\ntrainer = pl.Trainer(max_epochs=max_epochs, devices=1, accelerator=\"gpu\")\ntrainer.fit(BT_ImagenetPT_model, BT_Imagenet_dataloader)","metadata":{"execution":{"iopub.status.busy":"2023-11-26T18:15:25.228887Z","iopub.execute_input":"2023-11-26T18:15:25.229203Z","iopub.status.idle":"2023-11-26T18:49:29.582489Z","shell.execute_reply.started":"2023-11-26T18:15:25.229178Z","shell.execute_reply":"2023-11-26T18:49:29.581501Z"},"trusted":true},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":"Training: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"da5189fe13304e15a5f169e61e57bc0c"}},"metadata":{}},{"text":"IOPub message rate exceeded.\nThe Jupyter server will temporarily stop sending output\nto the client in order to avoid crashing it.\nTo change this limit, set the config variable\n`--ServerApp.iopub_msg_rate_limit`.\n\nCurrent values:\nServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\nServerApp.rate_limit_window=3.0 (secs)\n\n","name":"stderr","output_type":"stream"}]},{"cell_type":"markdown","source":"**DEFINING THE SWAV PRETRAINING MODEL**","metadata":{}},{"cell_type":"code","source":"SW_Imagenet_transform = SwaVTransform()\n# we ignore object detection annotations by setting target_transform to return 0\nSW_Imagenet_dataset = LightlyDataset(\n    input_dir=final_loc,\n    transform=SW_Imagenet_transform,\n)\n# or create a dataset from a folder containing images or videos:\n# dataset = LightlyDataset(\"path/to/folder\")\n\nSW_Imagenet_dataloader = torch.utils.data.DataLoader(\n    SW_Imagenet_dataset,   \n    batch_size=16,         \n    shuffle=True,           \n    num_workers=4\n)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-26T18:50:04.904879Z","iopub.execute_input":"2023-11-26T18:50:04.905224Z","iopub.status.idle":"2023-11-26T18:50:04.986852Z","shell.execute_reply.started":"2023-11-26T18:50:04.905199Z","shell.execute_reply":"2023-11-26T18:50:04.986075Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"max_epochs=10\nclass SwaV(pl.LightningModule):\n    def __init__(self):\n        super().__init__()\n        resnet = torchvision.models.resnet18()\n        self.backbone = nn.Sequential(*list(resnet.children())[:-1])\n        self.projection_head = SwaVProjectionHead(512, 512, 128)\n        self.prototypes = SwaVPrototypes(128, n_prototypes=512)\n        self.criterion = SwaVLoss()\n\n    def forward(self, x):\n        x = self.backbone(x).flatten(start_dim=1)\n        x = self.projection_head(x)\n        x = nn.functional.normalize(x, dim=1, p=2)\n        p = self.prototypes(x)\n        return p\n\n    def training_step(self, batch, batch_idx):\n        self.prototypes.normalize()\n        views = batch[0]\n        multi_crop_features = [self.forward(view.to(self.device)) for view in views]\n        high_resolution = multi_crop_features[:2]\n        low_resolution = multi_crop_features[2:]\n        loss = self.criterion(high_resolution, low_resolution)\n        return loss\n\n    def configure_optimizers(self):\n        optim = torch.optim.Adam(self.parameters(), lr=0.001)\n        return optim\n\ntorch.cuda.empty_cache()\nSW_ImagenetPT_model = SwaV()\ntrainer = pl.Trainer(max_epochs=max_epochs, devices=1, accelerator=\"gpu\")\ntrainer.fit(SW_ImagenetPT_model, SW_Imagenet_dataloader)","metadata":{"execution":{"iopub.status.busy":"2023-11-26T18:50:05.561589Z","iopub.execute_input":"2023-11-26T18:50:05.562314Z","iopub.status.idle":"2023-11-26T19:43:50.837724Z","shell.execute_reply.started":"2023-11-26T18:50:05.562283Z","shell.execute_reply":"2023-11-26T19:43:50.836694Z"},"trusted":true},"execution_count":14,"outputs":[{"output_type":"display_data","data":{"text/plain":"Training: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"29dec2a6262948e7b407e04168df4005"}},"metadata":{}}]},{"cell_type":"markdown","source":"**CREATING THE DATALOADERS FOR THE FINE-TUNING PROCESS**","metadata":{}},{"cell_type":"code","source":"def one_hot(n):\n    index={0:0,0.5:1,1:2,2:3}\n    #print(index)\n    #print(index[n])\n    y_new=np.zeros(4)\n    y_new[index[n]]=1\n    #print(y_new)\n    return y_new","metadata":{"execution":{"iopub.status.busy":"2023-11-27T02:13:38.884940Z","iopub.execute_input":"2023-11-27T02:13:38.885757Z","iopub.status.idle":"2023-11-27T02:13:38.892938Z","shell.execute_reply.started":"2023-11-27T02:13:38.885710Z","shell.execute_reply":"2023-11-27T02:13:38.891674Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"c=0\ndf_new = pd.DataFrame(columns=['IMG', 'CDR'])\ndef make_dataset(path,cdr):\n    \n    global c, df_new\n    \n    for i in os.listdir(path):\n        c+=1\n        image = cv2.imread(os.path.join(path,i))\n        image_np = np.array(image)\n        image_tensor = transforms.ToTensor()(image_np)\n        padded_image = transforms.CenterCrop((224, 224))(transforms.Pad(28)(image_tensor))\n        #print(padded_image.shape)\n        '''plt.imshow(padded_image.permute(1, 2, 0))\n        print('padded_image',padded_image.shape)'''  \n        \n        new_entry = {\n            'IMG': padded_image,\n            'CDR': cdr\n        } \n        df_new = pd.concat([df_new, pd.DataFrame([new_entry])], ignore_index=True)\n        #print(i)\n\n\nmake_dataset('/kaggle/input/alzheimers-dataset-4-class-of-images/Alzheimer_s Dataset/train/MildDemented',1)\nmake_dataset('/kaggle/input/alzheimers-dataset-4-class-of-images/Alzheimer_s Dataset/train/ModerateDemented',2)\nmake_dataset('/kaggle/input/alzheimers-dataset-4-class-of-images/Alzheimer_s Dataset/train/NonDemented',0)\nmake_dataset('/kaggle/input/alzheimers-dataset-4-class-of-images/Alzheimer_s Dataset/train/VeryMildDemented',0.5)\n        \nmake_dataset('/kaggle/input/alzheimers-dataset-4-class-of-images/Alzheimer_s Dataset/test/MildDemented',1)\nmake_dataset('/kaggle/input/alzheimers-dataset-4-class-of-images/Alzheimer_s Dataset/test/ModerateDemented',2)\nmake_dataset('/kaggle/input/alzheimers-dataset-4-class-of-images/Alzheimer_s Dataset/test/NonDemented',0)\nmake_dataset('/kaggle/input/alzheimers-dataset-4-class-of-images/Alzheimer_s Dataset/test/VeryMildDemented',0.5)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-27T02:13:38.896632Z","iopub.execute_input":"2023-11-27T02:13:38.897387Z","iopub.status.idle":"2023-11-27T02:14:31.643797Z","shell.execute_reply.started":"2023-11-27T02:13:38.897345Z","shell.execute_reply":"2023-11-27T02:14:31.642725Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"print(c,df_new.shape)\nprint(df_new['IMG'][0].shape)","metadata":{"execution":{"iopub.status.busy":"2023-11-27T02:14:31.645163Z","iopub.execute_input":"2023-11-27T02:14:31.645571Z","iopub.status.idle":"2023-11-27T02:14:31.658597Z","shell.execute_reply.started":"2023-11-27T02:14:31.645538Z","shell.execute_reply":"2023-11-27T02:14:31.657214Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"6400 (6400, 2)\ntorch.Size([3, 224, 224])\n","output_type":"stream"}]},{"cell_type":"code","source":"x=np.stack(df_new['IMG'].tolist())\ny=df_new['CDR']\n\ny_one_hot=[]\nfor i in y:\n    y_one_hot.append(one_hot(i)) ","metadata":{"execution":{"iopub.status.busy":"2023-11-27T02:14:31.660067Z","iopub.execute_input":"2023-11-27T02:14:31.660526Z","iopub.status.idle":"2023-11-27T02:14:33.704744Z","shell.execute_reply.started":"2023-11-27T02:14:31.660466Z","shell.execute_reply":"2023-11-27T02:14:33.703550Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"print(type(x))","metadata":{"execution":{"iopub.status.busy":"2023-11-27T02:14:33.706111Z","iopub.execute_input":"2023-11-27T02:14:33.706475Z","iopub.status.idle":"2023-11-27T02:14:33.711830Z","shell.execute_reply.started":"2023-11-27T02:14:33.706444Z","shell.execute_reply":"2023-11-27T02:14:33.710857Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"<class 'numpy.ndarray'>\n","output_type":"stream"}]},{"cell_type":"code","source":"x=torch.tensor(x)\ny=torch.Tensor(y_one_hot)\n\ndataset=TensorDataset(x,y)\n\ntrain_size=int(0.8*len(x))\nval_size=int(0.1*len(x))\ntemp_size=2*val_size\n\n#print(train_size,val_size,temp_size)\n\ntrain_dataset, temp_dataset = random_split(dataset, [train_size, temp_size])\nval_dataset,test_dataset=random_split(temp_dataset, [val_size,val_size])\n\n# Define batch size\nbatch_size = 8\n\n# Create a DataLoader for shuffling and batching\ntrain_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\nval_dataloader = DataLoader(val_dataset, batch_size=1, shuffle=True)\ntest_dataloader=DataLoader(test_dataset,batch_size=1,shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2023-11-27T02:14:33.713557Z","iopub.execute_input":"2023-11-27T02:14:33.713934Z","iopub.status.idle":"2023-11-27T02:14:35.816656Z","shell.execute_reply.started":"2023-11-27T02:14:33.713906Z","shell.execute_reply":"2023-11-27T02:14:35.815457Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_47/79332094.py:2: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:245.)\n  y=torch.Tensor(y_one_hot)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**DEFINING FUNCTIONS FOR THE FINE-TUNING**","metadata":{}},{"cell_type":"code","source":"def train_and_val(backbone):\n    \n    #training the models first on train_dataloader\n    \n    models=[]\n    for i in range(2):\n        models.append(ResnetSingleChannel(backbone,4))\n        \n   \n    \n    batch_sizes=[64,32]\n    \n    for model_no in range(2):\n        print(f'TRAINING MODEL {model_no+1}')\n        print('--------------------------------------------------------------')\n        fine_tune_opt = optim.Adam(models[model_no].parameters(), lr=0.001, weight_decay=0.0001)\n        ft_loss_fn= nn.CrossEntropyLoss()\n        \n        batch_size=batch_sizes[model_no]\n        \n        train_dataloader=DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n        val_dataloader = DataLoader(val_dataset, batch_size=1, shuffle=True)\n        \n\n        num_epochs = 8\n        total_steps=train_size//batch_size\n\n        for epoch in range(num_epochs):\n            i=0\n\n            for x_batch,y_batch in train_dataloader:\n                i+=1\n                outputs=models[model_no](torch.Tensor(x_batch))\n                \n                '''print('out',outputs.shape)\n                print('y',y_batch.shape)\n                print('out',outputs)\n                print('y',y_batch)'''\n                \n                loss = ft_loss_fn(outputs, y_batch)\n                fine_tune_opt.zero_grad()\n                loss.backward()\n                fine_tune_opt.step()\n\n                if (i+1) % 20 == 0:\n                    print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{total_steps}], Loss: {loss.item():.4f}')\n    \n    # performing validation on validation data_loader\n    best_model=-1\n    best_loss=np.inf\n    for model_no in range(2):\n        \n        loss_sum=0\n        \n        for x_batch,y_batch in val_dataloader:\n            outputs=models[model_no](torch.Tensor(x_batch))\n            loss = ft_loss_fn(outputs, y_batch)\n            loss_sum+=loss.item()\n            \n        if(loss_sum<best_loss):\n            best_model=model_no\n            best_loss=loss_sum\n    \n    return models[best_model]\n        \n        ","metadata":{"execution":{"iopub.status.busy":"2023-11-27T02:14:35.818155Z","iopub.execute_input":"2023-11-27T02:14:35.818588Z","iopub.status.idle":"2023-11-27T02:14:35.833584Z","shell.execute_reply.started":"2023-11-27T02:14:35.818559Z","shell.execute_reply":"2023-11-27T02:14:35.832623Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"def softmax(x):\n    return F.softmax(x, dim=-1)\n\ndef metrics(model):\n    \n    test_dataloader=DataLoader(test_dataset,batch_size=1,shuffle=True)\n    \n    y_pred_M=[]\n    y_true_M=[]\n    c=0\n    logloss_sum=0\n    \n    for x_batch,y_batch in test_dataloader:\n        \n        c+=1\n        y_pred=model(x_batch)\n\n        '''y_pred_M.append(np.argmax(y_pred.detach().numpy()))\n        y_true_M.append(np.argmax(y_batch.detach().numpy()))'''\n\n        softmax_probs = softmax(y_pred)\n\n        '''print(y_pred)\n        print(softmax_probs)\n        print(y_batch)'''\n\n        logloss = log_loss(y_batch.detach().numpy(), softmax_probs.detach().numpy())\n\n        logloss_sum+=logloss\n        #print(logloss) \n\n    return(logloss_sum/c)","metadata":{"execution":{"iopub.status.busy":"2023-11-27T02:14:35.836543Z","iopub.execute_input":"2023-11-27T02:14:35.837320Z","iopub.status.idle":"2023-11-27T02:14:35.851366Z","shell.execute_reply.started":"2023-11-27T02:14:35.837257Z","shell.execute_reply":"2023-11-27T02:14:35.850084Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"#MAKING A NEW NETWORK WHICH USES THE BACKBONE OF THE PRETRAINED MODEL, AND HAS AN INPUT LAYER TO TAKE IN A SINGLE CHANNEL IMAGE, AND THEN PASS INTO \n#BACKBONE, AND FINALLY OUTPUT LAYER WHICH PERFORMS REGRESSION\n\nclass ResnetSingleChannel(nn.Module):\n    def __init__(self,backbone,channels):\n        super(ResnetSingleChannel,self).__init__()\n        self.input=nn.Conv2d(3, 3, kernel_size=3, stride=1, padding=1, bias=False)\n        self.backbone=backbone\n        self.output=nn.Sequential(\n            nn.Flatten(),\n            nn.Linear(in_features=512, out_features=256),\n            nn.Linear(in_features=256, out_features=channels)\n        )\n        \n    def forward(self,x):\n        x=self.input(x)\n        x=self.backbone(x)\n        x=self.output(x)\n        \n        return x","metadata":{"execution":{"iopub.status.busy":"2023-11-27T02:14:35.852940Z","iopub.execute_input":"2023-11-27T02:14:35.855870Z","iopub.status.idle":"2023-11-27T02:14:35.865188Z","shell.execute_reply.started":"2023-11-27T02:14:35.855828Z","shell.execute_reply":"2023-11-27T02:14:35.864012Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"**TRAINING THE SIMCLR MODEL**","metadata":{}},{"cell_type":"code","source":"for layer in SimCLR_ImagenetPT_model.backbone:\n    for param in layer.parameters():\n        param.requires_grad = True\n        \nSC_MODEL=train_and_val(SimCLR_ImagenetPT_model.backbone)\nSC_M_2=metrics(SC_MODEL)","metadata":{"execution":{"iopub.status.busy":"2023-11-26T19:44:46.264455Z","iopub.execute_input":"2023-11-26T19:44:46.264827Z","iopub.status.idle":"2023-11-26T21:29:50.689849Z","shell.execute_reply.started":"2023-11-26T19:44:46.264791Z","shell.execute_reply":"2023-11-26T21:29:50.688575Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"TRAINING MODEL 1\n--------------------------------------------------------------\nEpoch [1/8], Step [20/80], Loss: 0.8038\nEpoch [1/8], Step [40/80], Loss: 0.7524\nEpoch [1/8], Step [60/80], Loss: 0.8903\nEpoch [1/8], Step [80/80], Loss: 0.9168\nEpoch [2/8], Step [20/80], Loss: 0.6241\nEpoch [2/8], Step [40/80], Loss: 0.6724\nEpoch [2/8], Step [60/80], Loss: 0.6062\nEpoch [2/8], Step [80/80], Loss: 0.6763\nEpoch [3/8], Step [20/80], Loss: 0.3164\nEpoch [3/8], Step [40/80], Loss: 0.4532\nEpoch [3/8], Step [60/80], Loss: 0.2445\nEpoch [3/8], Step [80/80], Loss: 0.3185\nEpoch [4/8], Step [20/80], Loss: 0.0805\nEpoch [4/8], Step [40/80], Loss: 0.1730\nEpoch [4/8], Step [60/80], Loss: 0.1191\nEpoch [4/8], Step [80/80], Loss: 0.2112\nEpoch [5/8], Step [20/80], Loss: 0.1413\nEpoch [5/8], Step [40/80], Loss: 0.1742\nEpoch [5/8], Step [60/80], Loss: 0.1327\nEpoch [5/8], Step [80/80], Loss: 0.1661\nEpoch [6/8], Step [20/80], Loss: 0.0354\nEpoch [6/8], Step [40/80], Loss: 0.1289\nEpoch [6/8], Step [60/80], Loss: 0.1061\nEpoch [6/8], Step [80/80], Loss: 0.0695\nEpoch [7/8], Step [20/80], Loss: 0.0509\nEpoch [7/8], Step [40/80], Loss: 0.0574\nEpoch [7/8], Step [60/80], Loss: 0.0210\nEpoch [7/8], Step [80/80], Loss: 0.1062\nEpoch [8/8], Step [20/80], Loss: 0.1098\nEpoch [8/8], Step [40/80], Loss: 0.0780\nEpoch [8/8], Step [60/80], Loss: 0.0797\nEpoch [8/8], Step [80/80], Loss: 0.2708\nTRAINING MODEL 2\n--------------------------------------------------------------\nEpoch [1/8], Step [20/160], Loss: 0.6713\nEpoch [1/8], Step [40/160], Loss: 0.3225\nEpoch [1/8], Step [60/160], Loss: 0.2427\nEpoch [1/8], Step [80/160], Loss: 0.2784\nEpoch [1/8], Step [100/160], Loss: 0.1193\nEpoch [1/8], Step [120/160], Loss: 0.1310\nEpoch [1/8], Step [140/160], Loss: 0.0451\nEpoch [1/8], Step [160/160], Loss: 0.0705\nEpoch [2/8], Step [20/160], Loss: 0.0415\nEpoch [2/8], Step [40/160], Loss: 0.0570\nEpoch [2/8], Step [60/160], Loss: 0.0062\nEpoch [2/8], Step [80/160], Loss: 0.0256\nEpoch [2/8], Step [100/160], Loss: 0.0558\nEpoch [2/8], Step [120/160], Loss: 0.0104\nEpoch [2/8], Step [140/160], Loss: 0.0497\nEpoch [2/8], Step [160/160], Loss: 0.1753\nEpoch [3/8], Step [20/160], Loss: 0.0979\nEpoch [3/8], Step [40/160], Loss: 0.3044\nEpoch [3/8], Step [60/160], Loss: 0.0513\nEpoch [3/8], Step [80/160], Loss: 0.0709\nEpoch [3/8], Step [100/160], Loss: 0.2589\nEpoch [3/8], Step [120/160], Loss: 0.0123\nEpoch [3/8], Step [140/160], Loss: 0.0059\nEpoch [3/8], Step [160/160], Loss: 0.0077\nEpoch [4/8], Step [20/160], Loss: 0.0099\nEpoch [4/8], Step [40/160], Loss: 0.0020\nEpoch [4/8], Step [60/160], Loss: 0.0102\nEpoch [4/8], Step [80/160], Loss: 0.0177\nEpoch [4/8], Step [100/160], Loss: 0.3004\nEpoch [4/8], Step [120/160], Loss: 0.1667\nEpoch [4/8], Step [140/160], Loss: 0.0587\nEpoch [4/8], Step [160/160], Loss: 0.2328\nEpoch [5/8], Step [20/160], Loss: 0.0112\nEpoch [5/8], Step [40/160], Loss: 0.0277\nEpoch [5/8], Step [60/160], Loss: 0.0186\nEpoch [5/8], Step [80/160], Loss: 0.0027\nEpoch [5/8], Step [100/160], Loss: 0.0111\nEpoch [5/8], Step [120/160], Loss: 0.0389\nEpoch [5/8], Step [140/160], Loss: 0.0661\nEpoch [5/8], Step [160/160], Loss: 0.0162\nEpoch [6/8], Step [20/160], Loss: 0.0887\nEpoch [6/8], Step [40/160], Loss: 0.0204\nEpoch [6/8], Step [60/160], Loss: 0.0068\nEpoch [6/8], Step [80/160], Loss: 0.0518\nEpoch [6/8], Step [100/160], Loss: 0.1220\nEpoch [6/8], Step [120/160], Loss: 0.0204\nEpoch [6/8], Step [140/160], Loss: 0.0033\nEpoch [6/8], Step [160/160], Loss: 0.0074\nEpoch [7/8], Step [20/160], Loss: 0.0100\nEpoch [7/8], Step [40/160], Loss: 0.0580\nEpoch [7/8], Step [60/160], Loss: 0.0266\nEpoch [7/8], Step [80/160], Loss: 0.0032\nEpoch [7/8], Step [100/160], Loss: 0.0447\nEpoch [7/8], Step [120/160], Loss: 0.0240\nEpoch [7/8], Step [140/160], Loss: 0.0026\nEpoch [7/8], Step [160/160], Loss: 0.0720\nEpoch [8/8], Step [20/160], Loss: 0.1506\nEpoch [8/8], Step [40/160], Loss: 0.0022\nEpoch [8/8], Step [60/160], Loss: 0.0031\nEpoch [8/8], Step [80/160], Loss: 0.0116\nEpoch [8/8], Step [100/160], Loss: 0.0015\nEpoch [8/8], Step [120/160], Loss: 0.0067\nEpoch [8/8], Step [140/160], Loss: 0.1266\nEpoch [8/8], Step [160/160], Loss: 0.0250\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[24], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m         param\u001b[38;5;241m.\u001b[39mrequires_grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m      5\u001b[0m SC_MODEL\u001b[38;5;241m=\u001b[39mtrain_and_val(SimCLR_ImagenetPT_model\u001b[38;5;241m.\u001b[39mbackbone)\n\u001b[0;32m----> 6\u001b[0m SC_M_2\u001b[38;5;241m=\u001b[39m\u001b[43mmetrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mSC_MODEL\u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[22], line 18\u001b[0m, in \u001b[0;36mmetrics\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m     13\u001b[0m y_pred\u001b[38;5;241m=\u001b[39mmodel(x_batch)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m'''y_pred_M.append(np.argmax(y_pred.detach().numpy()))\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;124;03my_true_M.append(np.argmax(y_batch.detach().numpy()))'''\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m softmax_probs \u001b[38;5;241m=\u001b[39m \u001b[43msoftmax\u001b[49m(y_pred)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m'''print(y_pred)\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;124;03mprint(softmax_probs)\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;124;03mprint(y_batch)'''\u001b[39;00m\n\u001b[1;32m     24\u001b[0m logloss \u001b[38;5;241m=\u001b[39m log_loss(y_batch\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy(), softmax_probs\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy())\n","\u001b[0;31mNameError\u001b[0m: name 'softmax' is not defined"],"ename":"NameError","evalue":"name 'softmax' is not defined","output_type":"error"}]},{"cell_type":"markdown","source":"**TRAINING THE BARLOW TWINS MODEL**","metadata":{}},{"cell_type":"code","source":"for layer in BT_ImagenetPT_model.backbone:\n    for param in layer.parameters():\n        param.requires_grad = True\n        \nBT_MODEL=train_and_val(BT_ImagenetPT_model.backbone)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-26T21:37:05.984111Z","iopub.execute_input":"2023-11-26T21:37:05.984514Z","iopub.status.idle":"2023-11-27T01:36:41.243386Z","shell.execute_reply.started":"2023-11-26T21:37:05.984480Z","shell.execute_reply":"2023-11-27T01:36:41.242540Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"TRAINING MODEL 1\n--------------------------------------------------------------\nEpoch [1/8], Step [20/80], Loss: 4.6292\nEpoch [1/8], Step [40/80], Loss: 1.2958\nEpoch [1/8], Step [60/80], Loss: 1.1957\nEpoch [1/8], Step [80/80], Loss: 0.8136\nEpoch [2/8], Step [20/80], Loss: 0.8975\nEpoch [2/8], Step [40/80], Loss: 1.3037\nEpoch [2/8], Step [60/80], Loss: 1.2433\nEpoch [2/8], Step [80/80], Loss: 1.0812\nEpoch [3/8], Step [20/80], Loss: 0.8990\nEpoch [3/8], Step [40/80], Loss: 0.9961\nEpoch [3/8], Step [60/80], Loss: 0.9847\nEpoch [3/8], Step [80/80], Loss: 1.0819\nEpoch [4/8], Step [20/80], Loss: 1.1181\nEpoch [4/8], Step [40/80], Loss: 1.0938\nEpoch [4/8], Step [60/80], Loss: 1.1866\nEpoch [4/8], Step [80/80], Loss: 0.9141\nEpoch [5/8], Step [20/80], Loss: 1.0640\nEpoch [5/8], Step [40/80], Loss: 1.1133\nEpoch [5/8], Step [60/80], Loss: 1.0680\nEpoch [5/8], Step [80/80], Loss: 1.0020\nEpoch [6/8], Step [20/80], Loss: 0.8915\nEpoch [6/8], Step [40/80], Loss: 1.0810\nEpoch [6/8], Step [60/80], Loss: 1.0640\nEpoch [6/8], Step [80/80], Loss: 1.1598\nEpoch [7/8], Step [20/80], Loss: 1.2670\nEpoch [7/8], Step [40/80], Loss: 0.8947\nEpoch [7/8], Step [60/80], Loss: 0.9201\nEpoch [7/8], Step [80/80], Loss: 1.1705\nEpoch [8/8], Step [20/80], Loss: 0.9525\nEpoch [8/8], Step [40/80], Loss: 0.8410\nEpoch [8/8], Step [60/80], Loss: 0.9881\nEpoch [8/8], Step [80/80], Loss: 0.9397\nTRAINING MODEL 2\n--------------------------------------------------------------\nEpoch [1/8], Step [20/160], Loss: 2.0885\nEpoch [1/8], Step [40/160], Loss: 1.4502\nEpoch [1/8], Step [60/160], Loss: 1.0446\nEpoch [1/8], Step [80/160], Loss: 1.2799\nEpoch [1/8], Step [100/160], Loss: 1.4463\nEpoch [1/8], Step [120/160], Loss: 1.3098\nEpoch [1/8], Step [140/160], Loss: 1.0124\nEpoch [1/8], Step [160/160], Loss: 1.2044\nEpoch [2/8], Step [20/160], Loss: 1.1047\nEpoch [2/8], Step [40/160], Loss: 1.3578\nEpoch [2/8], Step [60/160], Loss: 1.3755\nEpoch [2/8], Step [80/160], Loss: 1.4188\nEpoch [2/8], Step [100/160], Loss: 1.8845\nEpoch [2/8], Step [120/160], Loss: 1.1648\nEpoch [2/8], Step [140/160], Loss: 0.9293\nEpoch [2/8], Step [160/160], Loss: 1.1261\nEpoch [3/8], Step [20/160], Loss: 1.0753\nEpoch [3/8], Step [40/160], Loss: 1.2356\nEpoch [3/8], Step [60/160], Loss: 1.2011\nEpoch [3/8], Step [80/160], Loss: 1.0731\nEpoch [3/8], Step [100/160], Loss: 1.1707\nEpoch [3/8], Step [120/160], Loss: 1.0458\nEpoch [3/8], Step [140/160], Loss: 1.0111\nEpoch [3/8], Step [160/160], Loss: 1.0535\nEpoch [4/8], Step [20/160], Loss: 1.0088\nEpoch [4/8], Step [40/160], Loss: 0.9868\nEpoch [4/8], Step [60/160], Loss: 1.0752\nEpoch [4/8], Step [80/160], Loss: 1.4183\nEpoch [4/8], Step [100/160], Loss: 1.0955\nEpoch [4/8], Step [120/160], Loss: 1.1631\nEpoch [4/8], Step [140/160], Loss: 1.1170\nEpoch [4/8], Step [160/160], Loss: 1.0975\nEpoch [5/8], Step [20/160], Loss: 1.1320\nEpoch [5/8], Step [40/160], Loss: 1.0345\nEpoch [5/8], Step [60/160], Loss: 1.2304\nEpoch [5/8], Step [80/160], Loss: 0.9800\nEpoch [5/8], Step [100/160], Loss: 1.1196\nEpoch [5/8], Step [120/160], Loss: 1.3531\nEpoch [5/8], Step [140/160], Loss: 1.0983\nEpoch [5/8], Step [160/160], Loss: 1.1683\nEpoch [6/8], Step [20/160], Loss: 0.8741\nEpoch [6/8], Step [40/160], Loss: 1.2139\nEpoch [6/8], Step [60/160], Loss: 1.1045\nEpoch [6/8], Step [80/160], Loss: 1.1440\nEpoch [6/8], Step [100/160], Loss: 1.2421\nEpoch [6/8], Step [120/160], Loss: 1.1016\nEpoch [6/8], Step [140/160], Loss: 1.1399\nEpoch [6/8], Step [160/160], Loss: 1.1299\nEpoch [7/8], Step [20/160], Loss: 1.0357\nEpoch [7/8], Step [40/160], Loss: 1.2715\nEpoch [7/8], Step [60/160], Loss: 1.0213\nEpoch [7/8], Step [80/160], Loss: 1.0292\nEpoch [7/8], Step [100/160], Loss: 0.9967\nEpoch [7/8], Step [120/160], Loss: 1.2341\nEpoch [7/8], Step [140/160], Loss: 1.1317\nEpoch [7/8], Step [160/160], Loss: 1.1745\nEpoch [8/8], Step [20/160], Loss: 0.9948\nEpoch [8/8], Step [40/160], Loss: 0.9382\nEpoch [8/8], Step [60/160], Loss: 0.9254\nEpoch [8/8], Step [80/160], Loss: 0.9998\nEpoch [8/8], Step [100/160], Loss: 0.9764\nEpoch [8/8], Step [120/160], Loss: 1.0059\nEpoch [8/8], Step [140/160], Loss: 1.0258\nEpoch [8/8], Step [160/160], Loss: 0.9131\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**TRAINING THE SWAV MODEL**","metadata":{}},{"cell_type":"code","source":"SW_ImagenetPT_model_backbone=torch.load('/kaggle/input/weights/weights')","metadata":{"execution":{"iopub.status.busy":"2023-11-27T02:14:36.288024Z","iopub.execute_input":"2023-11-27T02:14:36.288884Z","iopub.status.idle":"2023-11-27T02:14:36.759739Z","shell.execute_reply.started":"2023-11-27T02:14:36.288846Z","shell.execute_reply":"2023-11-27T02:14:36.758581Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"for layer in SW_ImagenetPT_model_backbone:\n    for param in layer.parameters():\n        param.requires_grad = True\n        \nSW_MODEL=train_and_val(SW_ImagenetPT_model_backbone)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-27T02:15:01.759757Z","iopub.execute_input":"2023-11-27T02:15:01.760835Z","iopub.status.idle":"2023-11-27T05:08:44.588256Z","shell.execute_reply.started":"2023-11-27T02:15:01.760794Z","shell.execute_reply":"2023-11-27T05:08:44.586182Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"TRAINING MODEL 1\n--------------------------------------------------------------\nEpoch [1/8], Step [20/80], Loss: 1.1993\nEpoch [1/8], Step [40/80], Loss: 1.0096\nEpoch [1/8], Step [60/80], Loss: 1.0052\nEpoch [1/8], Step [80/80], Loss: 0.9624\nEpoch [2/8], Step [20/80], Loss: 0.8060\nEpoch [2/8], Step [40/80], Loss: 0.9999\nEpoch [2/8], Step [60/80], Loss: 0.7954\nEpoch [2/8], Step [80/80], Loss: 0.9277\nEpoch [3/8], Step [20/80], Loss: 0.7894\nEpoch [3/8], Step [40/80], Loss: 0.7859\nEpoch [3/8], Step [60/80], Loss: 0.8700\nEpoch [3/8], Step [80/80], Loss: 0.9596\nEpoch [4/8], Step [20/80], Loss: 0.7363\nEpoch [4/8], Step [40/80], Loss: 0.8580\nEpoch [4/8], Step [60/80], Loss: 0.8074\nEpoch [4/8], Step [80/80], Loss: 0.8336\nEpoch [5/8], Step [20/80], Loss: 0.8393\nEpoch [5/8], Step [40/80], Loss: 0.8133\nEpoch [5/8], Step [60/80], Loss: 0.6788\nEpoch [5/8], Step [80/80], Loss: 0.8695\nEpoch [6/8], Step [20/80], Loss: 0.7176\nEpoch [6/8], Step [40/80], Loss: 0.7619\nEpoch [6/8], Step [60/80], Loss: 0.7454\nEpoch [6/8], Step [80/80], Loss: 0.6818\nEpoch [7/8], Step [20/80], Loss: 0.7573\nEpoch [7/8], Step [40/80], Loss: 0.5376\nEpoch [7/8], Step [60/80], Loss: 0.5738\nEpoch [7/8], Step [80/80], Loss: 0.6582\nEpoch [8/8], Step [20/80], Loss: 0.5592\nEpoch [8/8], Step [40/80], Loss: 0.5165\nEpoch [8/8], Step [60/80], Loss: 0.5198\nEpoch [8/8], Step [80/80], Loss: 0.3832\nTRAINING MODEL 2\n--------------------------------------------------------------\nEpoch [1/8], Step [20/160], Loss: 1.0619\nEpoch [1/8], Step [40/160], Loss: 0.6768\nEpoch [1/8], Step [60/160], Loss: 1.0169\nEpoch [1/8], Step [80/160], Loss: 0.7315\nEpoch [1/8], Step [100/160], Loss: 0.4609\nEpoch [1/8], Step [120/160], Loss: 0.7243\nEpoch [1/8], Step [140/160], Loss: 0.5063\nEpoch [1/8], Step [160/160], Loss: 0.4949\nEpoch [2/8], Step [20/160], Loss: 0.6427\nEpoch [2/8], Step [40/160], Loss: 0.7838\nEpoch [2/8], Step [60/160], Loss: 0.5533\nEpoch [2/8], Step [80/160], Loss: 0.4256\nEpoch [2/8], Step [100/160], Loss: 0.3683\nEpoch [2/8], Step [120/160], Loss: 0.4329\nEpoch [2/8], Step [140/160], Loss: 0.6154\nEpoch [2/8], Step [160/160], Loss: 0.3565\nEpoch [3/8], Step [20/160], Loss: 0.3991\nEpoch [3/8], Step [40/160], Loss: 0.1782\nEpoch [3/8], Step [60/160], Loss: 0.2285\nEpoch [3/8], Step [80/160], Loss: 0.3783\nEpoch [3/8], Step [100/160], Loss: 0.4643\nEpoch [3/8], Step [120/160], Loss: 0.2646\nEpoch [3/8], Step [140/160], Loss: 0.3132\nEpoch [3/8], Step [160/160], Loss: 0.4360\nEpoch [4/8], Step [20/160], Loss: 0.1886\nEpoch [4/8], Step [40/160], Loss: 0.1505\nEpoch [4/8], Step [60/160], Loss: 0.1439\nEpoch [4/8], Step [80/160], Loss: 0.1630\nEpoch [4/8], Step [100/160], Loss: 0.3611\nEpoch [4/8], Step [120/160], Loss: 0.1573\nEpoch [4/8], Step [140/160], Loss: 0.4618\nEpoch [4/8], Step [160/160], Loss: 0.1435\nEpoch [5/8], Step [20/160], Loss: 0.0621\nEpoch [5/8], Step [40/160], Loss: 0.0235\nEpoch [5/8], Step [60/160], Loss: 0.2053\nEpoch [5/8], Step [80/160], Loss: 0.1010\nEpoch [5/8], Step [100/160], Loss: 0.1804\nEpoch [5/8], Step [120/160], Loss: 0.1860\nEpoch [5/8], Step [140/160], Loss: 0.2839\nEpoch [5/8], Step [160/160], Loss: 0.1699\nEpoch [6/8], Step [20/160], Loss: 0.1092\nEpoch [6/8], Step [40/160], Loss: 0.1535\nEpoch [6/8], Step [60/160], Loss: 0.1323\nEpoch [6/8], Step [80/160], Loss: 0.0561\nEpoch [6/8], Step [100/160], Loss: 0.0818\nEpoch [6/8], Step [120/160], Loss: 0.4429\nEpoch [6/8], Step [140/160], Loss: 0.1797\nEpoch [6/8], Step [160/160], Loss: 0.3201\nEpoch [7/8], Step [20/160], Loss: 0.1112\nEpoch [7/8], Step [40/160], Loss: 0.0249\nEpoch [7/8], Step [60/160], Loss: 0.0181\nEpoch [7/8], Step [80/160], Loss: 0.0584\nEpoch [7/8], Step [100/160], Loss: 0.0656\nEpoch [7/8], Step [120/160], Loss: 0.1361\nEpoch [7/8], Step [140/160], Loss: 0.0481\nEpoch [7/8], Step [160/160], Loss: 0.1151\nEpoch [8/8], Step [20/160], Loss: 0.0413\nEpoch [8/8], Step [40/160], Loss: 0.0452\nEpoch [8/8], Step [60/160], Loss: 0.0285\nEpoch [8/8], Step [80/160], Loss: 0.0615\nEpoch [8/8], Step [100/160], Loss: 0.1878\nEpoch [8/8], Step [120/160], Loss: 0.1073\nEpoch [8/8], Step [140/160], Loss: 0.2668\nEpoch [8/8], Step [160/160], Loss: 0.3001\n","output_type":"stream"}]},{"cell_type":"code","source":"SC_M_2=metrics(SC_MODEL)\nBT_M_2=metrics(BT_MODEL)","metadata":{"execution":{"iopub.status.busy":"2023-11-27T01:37:12.341129Z","iopub.execute_input":"2023-11-27T01:37:12.341503Z","iopub.status.idle":"2023-11-27T01:39:19.450061Z","shell.execute_reply.started":"2023-11-27T01:37:12.341472Z","shell.execute_reply":"2023-11-27T01:39:19.449204Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"SW_M_2=metrics(SW_MODEL)","metadata":{"execution":{"iopub.status.busy":"2023-11-27T05:09:39.503880Z","iopub.execute_input":"2023-11-27T05:09:39.504966Z","iopub.status.idle":"2023-11-27T05:10:15.889301Z","shell.execute_reply.started":"2023-11-27T05:09:39.504864Z","shell.execute_reply":"2023-11-27T05:10:15.888237Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"**PRINTING THE METRICS**","metadata":{}},{"cell_type":"code","source":"print('SimCLR',SC_M_2)\nprint('Barlow',BT_M_2)","metadata":{"execution":{"iopub.status.busy":"2023-11-27T01:39:19.451929Z","iopub.execute_input":"2023-11-27T01:39:19.452312Z","iopub.status.idle":"2023-11-27T01:39:19.458149Z","shell.execute_reply.started":"2023-11-27T01:39:19.452278Z","shell.execute_reply":"2023-11-27T01:39:19.457197Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stdout","text":"SimCLR 1.700522285293879\nBarlow 1.0983590523172133\n","output_type":"stream"}]},{"cell_type":"code","source":"print('SwAV',SW_M_2)","metadata":{"execution":{"iopub.status.busy":"2023-11-27T05:10:15.891562Z","iopub.execute_input":"2023-11-27T05:10:15.892014Z","iopub.status.idle":"2023-11-27T05:10:15.899448Z","shell.execute_reply.started":"2023-11-27T05:10:15.891970Z","shell.execute_reply":"2023-11-27T05:10:15.898347Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"SwAV 1.191522333303905\n","output_type":"stream"}]}]}
