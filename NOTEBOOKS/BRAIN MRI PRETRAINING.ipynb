{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":861496,"sourceType":"datasetVersion","datasetId":457093},{"sourceId":995044,"sourceType":"datasetVersion","datasetId":545156},{"sourceId":6677526,"sourceType":"datasetVersion","datasetId":3852514},{"sourceId":7013184,"sourceType":"datasetVersion","datasetId":4032317},{"sourceId":7013189,"sourceType":"datasetVersion","datasetId":4032321},{"sourceId":7013197,"sourceType":"datasetVersion","datasetId":4032329}],"dockerImageVersionId":30587,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**INSTALLING THE REQUIRED DEPENDENCIES**","metadata":{}},{"cell_type":"code","source":"!pip install lightly -q","metadata":{"execution":{"iopub.status.busy":"2023-11-26T09:50:11.159718Z","iopub.execute_input":"2023-11-26T09:50:11.160000Z","iopub.status.idle":"2023-11-26T09:50:28.332171Z","shell.execute_reply.started":"2023-11-26T09:50:11.159975Z","shell.execute_reply":"2023-11-26T09:50:28.330777Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"**IMPORTING THE DEPENDENCIES**","metadata":{}},{"cell_type":"code","source":"#dependencies for file management and data visualisation\nimport os\nimport shutil\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport nibabel as nib\nimport re\nfrom tqdm import tqdm\nimport pandas as pd\nimport gc\nimport psutil\nfrom matplotlib.animation import FuncAnimation\nimport seaborn as sns\nfrom IPython.display import HTML\nimport cv2\n\n#pretraining dependencies\nfrom lightly.data import LightlyDataset\n\n#pretraining of SIMCLR MODEL\nfrom lightly.transforms.simclr_transform import SimCLRTransform\nfrom lightly.loss import NTXentLoss\nfrom lightly.models.modules.heads import SimCLRProjectionHead\n\n#pretraining of BarlowTwins MODEL\nfrom lightly.loss import BarlowTwinsLoss\nfrom lightly.models.modules import BarlowTwinsProjectionHead\nfrom lightly.transforms.byol_transform import (\n    BYOLTransform,\n    BYOLView1Transform,\n    BYOLView2Transform,\n)\n\n#pretraining on SWaV MODEL\nfrom lightly.loss import SwaVLoss\nfrom lightly.models.modules import SwaVProjectionHead, SwaVPrototypes\nfrom lightly.transforms.swav_transform import SwaVTransform\n\n\n#fine-tuning the models\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import TensorDataset, DataLoader , random_split\nimport pytorch_lightning as pl\nimport torchvision\nfrom torchvision import transforms\nfrom pytorch_lightning import seed_everything\n\n#evaluating the models\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report , log_loss\n\nseed_value = 50\n\ntorch.manual_seed(seed_value)\n\nif torch.cuda.is_available():\n    torch.cuda.manual_seed_all(seed_value)\n\nseed_everything(42)","metadata":{"execution":{"iopub.status.busy":"2023-11-26T18:58:00.266056Z","iopub.execute_input":"2023-11-26T18:58:00.266452Z","iopub.status.idle":"2023-11-26T18:58:00.285755Z","shell.execute_reply.started":"2023-11-26T18:58:00.266419Z","shell.execute_reply":"2023-11-26T18:58:00.284811Z"},"trusted":true},"execution_count":55,"outputs":[{"execution_count":55,"output_type":"execute_result","data":{"text/plain":"42"},"metadata":{}}]},{"cell_type":"markdown","source":"**GETTING ALL THE MRI IMAGES INTO ONE SINGLE FOLDER**","metadata":{}},{"cell_type":"code","source":"final_loc='/kaggle/data'\nc=0","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-11-26T09:50:37.488572Z","iopub.execute_input":"2023-11-26T09:50:37.489030Z","iopub.status.idle":"2023-11-26T09:50:37.492961Z","shell.execute_reply.started":"2023-11-26T09:50:37.489004Z","shell.execute_reply":"2023-11-26T09:50:37.492134Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"mri1_no='/kaggle/input/brain-mri1/no'\nmri1_yes='/kaggle/input/brain-mri1/yes'\n\nos.makedirs(final_loc,exist_ok=True)\nfor file in os.listdir(mri1_no):\n    c+=1\n    \n    file_path=os.path.join(mri1_no,file)\n    ext=file[-4:]\n    if(ext=='jpeg'):\n        ext='.jpeg'\n    new_filename=str(c)+ext\n    final_path=os.path.join(final_loc,new_filename)\n    \n    shutil.copy(file_path, final_path)\n    \nfor file in os.listdir(mri1_yes):\n    c+=1\n    \n    file_path=os.path.join(mri1_yes,file)\n    ext=file[-4:]\n    if(ext=='jpeg'):\n        ext='.jpeg'\n    new_filename=str(c)+ext\n    final_path=os.path.join(final_loc,new_filename)\n    \n    shutil.copy(file_path, final_path)\n    \n    ","metadata":{"execution":{"iopub.status.busy":"2023-11-26T09:50:37.495225Z","iopub.execute_input":"2023-11-26T09:50:37.495809Z","iopub.status.idle":"2023-11-26T09:50:39.361695Z","shell.execute_reply.started":"2023-11-26T09:50:37.495742Z","shell.execute_reply":"2023-11-26T09:50:39.360903Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"mri2_test='/kaggle/input/brain-mri2/Testing'\nmri2_train='/kaggle/input/brain-mri2/Training'\n\ntypes=['glioma_tumor','meningioma_tumor','no_tumor','pituitary_tumor']\n\nfor i in range(4):\n    folder_path=os.path.join(mri2_test,types[i])\n    for file in os.listdir(folder_path):\n        c+=1\n        file_path=os.path.join(folder_path,file)\n        new_filename=str(c)+'.jpg'\n        final_path=os.path.join(final_loc,new_filename)\n        \n        shutil.copy(file_path, final_path)\n\nfor i in range(4):\n    folder_path=os.path.join(mri2_train,types[i])\n    for file in os.listdir(folder_path):\n        c+=1\n        file_path=os.path.join(folder_path,file)\n        new_filename=str(c)+'.jpg'\n        final_path=os.path.join(final_loc,new_filename)\n        \n        shutil.copy(file_path, final_path)      ","metadata":{"execution":{"iopub.status.busy":"2023-11-26T09:50:39.363175Z","iopub.execute_input":"2023-11-26T09:50:39.363532Z","iopub.status.idle":"2023-11-26T09:51:05.551345Z","shell.execute_reply.started":"2023-11-26T09:50:39.363498Z","shell.execute_reply":"2023-11-26T09:51:05.550548Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"mri3_yes='/kaggle/input/brain-mri3/yes'\nmri3_no='/kaggle/input/brain-mri3/no'\n\nfor file in os.listdir(mri3_yes):\n    c+=1\n    file_path=os.path.join(mri3_yes,file)\n    new_filename=str(c)+'.jpg'\n    final_path=os.path.join(final_loc,new_filename)\n    \n    shutil.copy(file_path,final_path)\n    \nfor file in os.listdir(mri3_no):\n    c+=1\n    file_path=os.path.join(mri3_no,file)\n    new_filename=str(c)+'.jpg'\n    final_path=os.path.join(final_loc,new_filename)\n    \n    shutil.copy(file_path,final_path)","metadata":{"execution":{"iopub.status.busy":"2023-11-26T09:51:05.552430Z","iopub.execute_input":"2023-11-26T09:51:05.552690Z","iopub.status.idle":"2023-11-26T09:51:32.661384Z","shell.execute_reply.started":"2023-11-26T09:51:05.552667Z","shell.execute_reply":"2023-11-26T09:51:32.660576Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"counter=0\nfor i in os.listdir(final_loc):\n    counter+=1\nprint(c,counter)","metadata":{"execution":{"iopub.status.busy":"2023-11-26T09:51:32.662435Z","iopub.execute_input":"2023-11-26T09:51:32.662690Z","iopub.status.idle":"2023-11-26T09:51:32.672923Z","shell.execute_reply.started":"2023-11-26T09:51:32.662668Z","shell.execute_reply":"2023-11-26T09:51:32.672155Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"6517 6517\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**MAKING THE SIMCLR MODEL NOW**","metadata":{}},{"cell_type":"code","source":"input_size=32\nSC_Imagenet_transform = SimCLRTransform(input_size=input_size)\n\n# Create a dataset from your image folder.\nSC_Imagenet_dataset = LightlyDataset(\n    input_dir=final_loc,\n    transform=SC_Imagenet_transform,\n)\n\n# Build a PyTorch dataloader.\nSC_Imagenet_dataloader = torch.utils.data.DataLoader(\n    SC_Imagenet_dataset,                # Pass the dataset to the dataloader.\n    batch_size=16,         # A large batch size helps with learning.\n    shuffle=True,           # Shuffling is important!\n    num_workers=4\n)","metadata":{"execution":{"iopub.status.busy":"2023-11-26T09:51:32.673983Z","iopub.execute_input":"2023-11-26T09:51:32.674265Z","iopub.status.idle":"2023-11-26T09:51:32.720552Z","shell.execute_reply.started":"2023-11-26T09:51:32.674241Z","shell.execute_reply":"2023-11-26T09:51:32.719797Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"max_epochs=15\n\nclass SimCLR(pl.LightningModule):\n    def __init__(self):\n        super().__init__()\n        resnet = torchvision.models.resnet18()\n        self.backbone = nn.Sequential(*list(resnet.children())[:-1])\n\n        \n        self.projection_head = SimCLRProjectionHead(512,512,2048)\n        #1st parameter -> input size (from the last layer of the resnet backbone)\n        #2nd parameter -> hidden size\n        #3rd parameter -> output size\n\n        self.criterion = NTXentLoss()\n\n    def forward(self, x):\n        h = self.backbone(x).flatten(start_dim=1)\n        z = self.projection_head(h)\n        return z\n\n    def training_step(self, batch, batch_idx):\n        (x0, x1), _, _ = batch\n        z0 = self.forward(x0)\n        z1 = self.forward(x1)\n        loss = self.criterion(z0, z1)\n        return loss\n\n    def configure_optimizers(self):\n        optim = torch.optim.SGD(\n            self.parameters(), lr=6e-2, momentum=0.9, weight_decay=5e-4\n        )\n        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optim, max_epochs)\n        return [optim],[scheduler]\n    \ntorch.cuda.empty_cache()\nSimCLR_ImagenetPT_model = SimCLR()\ntrainer = pl.Trainer(max_epochs=max_epochs, devices=1, accelerator=\"gpu\")\ntrainer.fit(SimCLR_ImagenetPT_model, SC_Imagenet_dataloader)","metadata":{"execution":{"iopub.status.busy":"2023-11-26T10:30:59.393752Z","iopub.execute_input":"2023-11-26T10:30:59.394141Z","iopub.status.idle":"2023-11-26T10:35:18.003196Z","shell.execute_reply.started":"2023-11-26T10:30:59.394108Z","shell.execute_reply":"2023-11-26T10:35:18.002271Z"},"trusted":true},"execution_count":24,"outputs":[{"output_type":"display_data","data":{"text/plain":"Training: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a5dbe79aefa5478997e9241c96eea60d"}},"metadata":{}}]},{"cell_type":"markdown","source":"**MAKING THE BARLOWTWINS MODEL NOW**","metadata":{}},{"cell_type":"code","source":"BT_Imagenet_transform = BYOLTransform(\n    view_1_transform=BYOLView1Transform(input_size=32, gaussian_blur=0.0),\n    view_2_transform=BYOLView2Transform(input_size=32, gaussian_blur=0.0),\n)\n\nBT_Imagenet_dataset = LightlyDataset(\n    input_dir=final_loc,\n    transform=BT_Imagenet_transform,\n)\n\nBT_Imagenet_dataloader = torch.utils.data.DataLoader(\n    BT_Imagenet_dataset,   \n    batch_size=16,         \n    shuffle=True,           \n    num_workers=4\n)","metadata":{"execution":{"iopub.status.busy":"2023-11-26T10:35:18.005178Z","iopub.execute_input":"2023-11-26T10:35:18.005489Z","iopub.status.idle":"2023-11-26T10:35:18.044646Z","shell.execute_reply.started":"2023-11-26T10:35:18.005459Z","shell.execute_reply":"2023-11-26T10:35:18.043958Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"max_epochs=15\n\nclass BarlowTwins(pl.LightningModule):\n    def __init__(self):\n        super().__init__()\n        resnet = torchvision.models.resnet18()\n        self.backbone = nn.Sequential(*list(resnet.children())[:-1])\n        self.projection_head = BarlowTwinsProjectionHead(512, 2048, 2048)\n        self.criterion = BarlowTwinsLoss()\n\n    def forward(self, x):\n        x = self.backbone(x).flatten(start_dim=1)\n        z = self.projection_head(x)\n        return z\n\n    def training_step(self, batch, batch_index):\n        (x0, x1) = batch[0]\n        z0 = self.forward(x0)\n        z1 = self.forward(x1)\n        loss = self.criterion(z0, z1)\n        return loss\n\n    def configure_optimizers(self):\n        optim = torch.optim.SGD(self.parameters(), lr=0.06)\n        return optim\n        \ntorch.cuda.empty_cache()\nBT_ImagenetPT_model = BarlowTwins()\ntrainer = pl.Trainer(max_epochs=max_epochs, devices=1, accelerator=\"gpu\")\ntrainer.fit(BT_ImagenetPT_model, BT_Imagenet_dataloader)","metadata":{"execution":{"iopub.status.busy":"2023-11-26T10:35:18.045629Z","iopub.execute_input":"2023-11-26T10:35:18.045908Z","iopub.status.idle":"2023-11-26T10:39:28.785163Z","shell.execute_reply.started":"2023-11-26T10:35:18.045882Z","shell.execute_reply":"2023-11-26T10:39:28.784296Z"},"trusted":true},"execution_count":26,"outputs":[{"output_type":"display_data","data":{"text/plain":"Training: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fd9e9d253a9b4975895bf33aa4e7e3a7"}},"metadata":{}}]},{"cell_type":"markdown","source":"**PRETRAINING OVER SWAV MODEL NOW**","metadata":{}},{"cell_type":"code","source":"SW_Imagenet_transform = SwaVTransform()\n# we ignore object detection annotations by setting target_transform to return 0\nSW_Imagenet_dataset = LightlyDataset(\n    input_dir=final_loc,\n    transform=SW_Imagenet_transform,\n)\n# or create a dataset from a folder containing images or videos:\n# dataset = LightlyDataset(\"path/to/folder\")\n\nSW_Imagenet_dataloader = torch.utils.data.DataLoader(\n    SW_Imagenet_dataset,   \n    batch_size=16,         \n    shuffle=True,           \n    num_workers=4\n)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-26T10:39:28.787734Z","iopub.execute_input":"2023-11-26T10:39:28.788414Z","iopub.status.idle":"2023-11-26T10:39:28.826638Z","shell.execute_reply.started":"2023-11-26T10:39:28.788380Z","shell.execute_reply":"2023-11-26T10:39:28.825899Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"max_epochs=10\nclass SwaV(pl.LightningModule):\n    def __init__(self):\n        super().__init__()\n        resnet = torchvision.models.resnet18()\n        self.backbone = nn.Sequential(*list(resnet.children())[:-1])\n        self.projection_head = SwaVProjectionHead(512, 512, 128)\n        self.prototypes = SwaVPrototypes(128, n_prototypes=512)\n        self.criterion = SwaVLoss()\n\n    def forward(self, x):\n        x = self.backbone(x).flatten(start_dim=1)\n        x = self.projection_head(x)\n        x = nn.functional.normalize(x, dim=1, p=2)\n        p = self.prototypes(x)\n        return p\n\n    def training_step(self, batch, batch_idx):\n        self.prototypes.normalize()\n        views = batch[0]\n        multi_crop_features = [self.forward(view.to(self.device)) for view in views]\n        high_resolution = multi_crop_features[:2]\n        low_resolution = multi_crop_features[2:]\n        loss = self.criterion(high_resolution, low_resolution)\n        return loss\n\n    def configure_optimizers(self):\n        optim = torch.optim.Adam(self.parameters(), lr=0.001)\n        return optim\n\ntorch.cuda.empty_cache()\nSW_ImagenetPT_model = SwaV()\ntrainer = pl.Trainer(max_epochs=max_epochs, devices=1, accelerator=\"gpu\")\ntrainer.fit(SW_ImagenetPT_model, SW_Imagenet_dataloader)","metadata":{"execution":{"iopub.status.busy":"2023-11-26T10:39:28.827753Z","iopub.execute_input":"2023-11-26T10:39:28.828057Z","iopub.status.idle":"2023-11-26T10:53:40.595708Z","shell.execute_reply.started":"2023-11-26T10:39:28.828031Z","shell.execute_reply":"2023-11-26T10:53:40.594910Z"},"trusted":true},"execution_count":28,"outputs":[{"output_type":"display_data","data":{"text/plain":"Training: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9a9dbfc1d1f441049e45e2686136eae4"}},"metadata":{}}]},{"cell_type":"markdown","source":"**NOW THAT THE PRETRAINING IS DONE, WE DEFINE THE TRAIN AND TEST DATALOADER FOR THE FINE-TUNING TASK**","metadata":{}},{"cell_type":"code","source":"def one_hot(n):\n    index={0:0,0.5:1,1:2,2:3}\n    #print(index)\n    #print(index[n])\n    y_new=np.zeros(4)\n    y_new[index[n]]=1\n    #print(y_new)\n    return y_new","metadata":{"execution":{"iopub.status.busy":"2023-11-26T10:53:40.597816Z","iopub.execute_input":"2023-11-26T10:53:40.598789Z","iopub.status.idle":"2023-11-26T10:53:40.604676Z","shell.execute_reply.started":"2023-11-26T10:53:40.598746Z","shell.execute_reply":"2023-11-26T10:53:40.603567Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"c=0\ndf_new = pd.DataFrame(columns=['IMG', 'CDR'])\ndef make_dataset(path,cdr):\n    \n    global c, df_new\n    \n    for i in os.listdir(path):\n        c+=1\n        image = cv2.imread(os.path.join(path,i))\n        image_np = np.array(image)\n        image_tensor = transforms.ToTensor()(image_np)\n        padded_image = transforms.CenterCrop((224, 224))(transforms.Pad(28)(image_tensor))\n        #print(padded_image.shape)\n        '''plt.imshow(padded_image.permute(1, 2, 0))\n        print('padded_image',padded_image.shape)'''  \n        \n        new_entry = {\n            'IMG': padded_image,\n            'CDR': cdr\n        } \n        df_new = pd.concat([df_new, pd.DataFrame([new_entry])], ignore_index=True)\n        #print(i)\n\n\nmake_dataset('/kaggle/input/alzheimers-dataset-4-class-of-images/Alzheimer_s Dataset/train/MildDemented',1)\nmake_dataset('/kaggle/input/alzheimers-dataset-4-class-of-images/Alzheimer_s Dataset/train/ModerateDemented',2)\nmake_dataset('/kaggle/input/alzheimers-dataset-4-class-of-images/Alzheimer_s Dataset/train/NonDemented',0)\nmake_dataset('/kaggle/input/alzheimers-dataset-4-class-of-images/Alzheimer_s Dataset/train/VeryMildDemented',0.5)\n        \nmake_dataset('/kaggle/input/alzheimers-dataset-4-class-of-images/Alzheimer_s Dataset/test/MildDemented',1)\nmake_dataset('/kaggle/input/alzheimers-dataset-4-class-of-images/Alzheimer_s Dataset/test/ModerateDemented',2)\nmake_dataset('/kaggle/input/alzheimers-dataset-4-class-of-images/Alzheimer_s Dataset/test/NonDemented',0)\nmake_dataset('/kaggle/input/alzheimers-dataset-4-class-of-images/Alzheimer_s Dataset/test/VeryMildDemented',0.5)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-26T10:53:40.605911Z","iopub.execute_input":"2023-11-26T10:53:40.606177Z","iopub.status.idle":"2023-11-26T10:54:02.354112Z","shell.execute_reply.started":"2023-11-26T10:53:40.606152Z","shell.execute_reply":"2023-11-26T10:54:02.353274Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"print(c,df_new.shape)\nprint(df_new['IMG'][0].shape)","metadata":{"execution":{"iopub.status.busy":"2023-11-26T10:54:02.355286Z","iopub.execute_input":"2023-11-26T10:54:02.355583Z","iopub.status.idle":"2023-11-26T10:54:02.361177Z","shell.execute_reply.started":"2023-11-26T10:54:02.355557Z","shell.execute_reply":"2023-11-26T10:54:02.360193Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"6400 (6400, 2)\ntorch.Size([3, 224, 224])\n","output_type":"stream"}]},{"cell_type":"code","source":"x=np.stack(df_new['IMG'].tolist())\ny=df_new['CDR']\n\ny_one_hot=[]\nfor i in y:\n    y_one_hot.append(one_hot(i)) ","metadata":{"execution":{"iopub.status.busy":"2023-11-26T10:54:02.362465Z","iopub.execute_input":"2023-11-26T10:54:02.363076Z","iopub.status.idle":"2023-11-26T10:54:03.556859Z","shell.execute_reply.started":"2023-11-26T10:54:02.363020Z","shell.execute_reply":"2023-11-26T10:54:03.556068Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"print(type(x))","metadata":{"execution":{"iopub.status.busy":"2023-11-26T10:54:03.559779Z","iopub.execute_input":"2023-11-26T10:54:03.560072Z","iopub.status.idle":"2023-11-26T10:54:03.564524Z","shell.execute_reply.started":"2023-11-26T10:54:03.560047Z","shell.execute_reply":"2023-11-26T10:54:03.563663Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stdout","text":"<class 'numpy.ndarray'>\n","output_type":"stream"}]},{"cell_type":"code","source":"x=torch.tensor(x)\ny=torch.Tensor(y_one_hot)\n\ndataset=TensorDataset(x,y)\n\ntrain_size=int(0.6*len(x))\nval_size=int(0.2*len(x))\ntemp_size=2*val_size\n\n#print(train_size,val_size,temp_size)\n\ntrain_dataset, temp_dataset = random_split(dataset, [train_size, temp_size])\nval_dataset,test_dataset=random_split(temp_dataset, [val_size,val_size])\n\n# Define batch size\n#batch_size = 8\n\n# Create a DataLoader for shuffling and batching\n'''train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\nval_dataloader = DataLoader(val_dataset, batch_size=1, shuffle=True)\ntest_dataloader=DataLoader(test_dataset,batch_size=1,shuffle=True)'''","metadata":{"execution":{"iopub.status.busy":"2023-11-26T10:54:03.565601Z","iopub.execute_input":"2023-11-26T10:54:03.565889Z","iopub.status.idle":"2023-11-26T10:54:04.972569Z","shell.execute_reply.started":"2023-11-26T10:54:03.565842Z","shell.execute_reply":"2023-11-26T10:54:04.971557Z"},"trusted":true},"execution_count":34,"outputs":[{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"'train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\\nval_dataloader = DataLoader(val_dataset, batch_size=1, shuffle=True)\\ntest_dataloader=DataLoader(test_dataset,batch_size=1,shuffle=True)'"},"metadata":{}}]},{"cell_type":"markdown","source":"**MAKING FUNCTIONS FOR THE FINE-TUNING TASK**","metadata":{}},{"cell_type":"code","source":"def train_and_val(backbone):\n    \n    #training the models first on train_dataloader\n    \n    models=[]\n    for i in range(2):\n        models.append(ResnetSingleChannel(backbone,4))\n        \n   \n    \n    batch_sizes=[64,32]\n    \n    for model_no in range(2):\n        print(f'TRAINING MODEL {model_no+1}')\n        print('--------------------------------------------------------------')\n        fine_tune_opt = optim.Adam(models[model_no].parameters(), lr=0.001, weight_decay=0.0001)\n        ft_loss_fn= nn.CrossEntropyLoss()\n        \n        batch_size=batch_sizes[model_no]\n        \n        train_dataloader=DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n        val_dataloader = DataLoader(val_dataset, batch_size=1, shuffle=True)\n        \n\n        num_epochs = 8\n        total_steps=train_size//batch_size\n\n        for epoch in range(num_epochs):\n            i=0\n\n            for x_batch,y_batch in train_dataloader:\n                i+=1\n                outputs=models[model_no](torch.Tensor(x_batch))\n                \n                '''print('out',outputs.shape)\n                print('y',y_batch.shape)\n                print('out',outputs)\n                print('y',y_batch)'''\n                \n                loss = ft_loss_fn(outputs, y_batch)\n                fine_tune_opt.zero_grad()\n                loss.backward()\n                fine_tune_opt.step()\n\n                if (i+1) % 20 == 0:\n                    print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{total_steps}], Loss: {loss.item():.4f}')\n    \n    # performing validation on validation data_loader\n    best_model=-1\n    best_loss=np.inf\n    for model_no in range(2):\n        \n        loss_sum=0\n        \n        for x_batch,y_batch in val_dataloader:\n            outputs=models[model_no](torch.Tensor(x_batch))\n            loss = ft_loss_fn(outputs, y_batch)\n            loss_sum+=loss.item()\n            \n        if(loss_sum<best_loss):\n            best_model=model_no\n            best_loss=loss_sum\n    \n    return models[best_model]\n        \n        ","metadata":{"execution":{"iopub.status.busy":"2023-11-26T10:54:04.973751Z","iopub.execute_input":"2023-11-26T10:54:04.974063Z","iopub.status.idle":"2023-11-26T10:54:04.985185Z","shell.execute_reply.started":"2023-11-26T10:54:04.974036Z","shell.execute_reply":"2023-11-26T10:54:04.984227Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"def softmax(x):\n    return F.softmax(x,dim=-1)\n\n\ndef metrics(model):\n    \n    test_dataloader=DataLoader(test_dataset,batch_size=1,shuffle=True)\n    \n    y_pred_M=[]\n    y_true_M=[]\n    c=0\n    logloss_sum=0\n    \n    for x_batch,y_batch in test_dataloader:\n        \n        c+=1\n        y_pred=model(x_batch)\n\n        '''y_pred_M.append(np.argmax(y_pred.detach().numpy()))\n        y_true_M.append(np.argmax(y_batch.detach().numpy()))'''\n\n        softmax_probs = softmax(y_pred)\n\n        '''print(y_pred)\n        print(softmax_probs)\n        print(y_batch)'''\n\n        logloss = log_loss(y_batch.detach().numpy(), softmax_probs.detach().numpy())\n\n        logloss_sum+=logloss\n        #print(logloss) \n\n    return(logloss_sum/c)","metadata":{"execution":{"iopub.status.busy":"2023-11-26T18:58:18.367311Z","iopub.execute_input":"2023-11-26T18:58:18.367676Z","iopub.status.idle":"2023-11-26T18:58:18.374979Z","shell.execute_reply.started":"2023-11-26T18:58:18.367644Z","shell.execute_reply":"2023-11-26T18:58:18.374075Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"#MAKING A NEW NETWORK WHICH USES THE BACKBONE OF THE PRETRAINED MODEL, AND HAS AN INPUT LAYER TO TAKE IN A SINGLE CHANNEL IMAGE, AND THEN PASS INTO \n#BACKBONE, AND FINALLY OUTPUT LAYER WHICH PERFORMS REGRESSION\n\nclass ResnetSingleChannel(nn.Module):\n    def __init__(self,backbone,channels):\n        super(ResnetSingleChannel,self).__init__()\n        self.input=nn.Conv2d(3, 3, kernel_size=3, stride=1, padding=1, bias=False)\n        self.backbone=backbone\n        self.output=nn.Sequential(\n            nn.Flatten(),\n            nn.Linear(in_features=512, out_features=256),\n            nn.Linear(in_features=256, out_features=channels)\n        )\n        \n    def forward(self,x):\n        x=self.input(x)\n        x=self.backbone(x)\n        x=self.output(x)\n        \n        return x","metadata":{"execution":{"iopub.status.busy":"2023-11-26T10:54:05.002085Z","iopub.execute_input":"2023-11-26T10:54:05.002368Z","iopub.status.idle":"2023-11-26T10:54:05.014322Z","shell.execute_reply.started":"2023-11-26T10:54:05.002343Z","shell.execute_reply":"2023-11-26T10:54:05.013416Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"markdown","source":"**TRAINING OVER THE SIMCLR MODEL**","metadata":{}},{"cell_type":"code","source":"for layer in SimCLR_ImagenetPT_model.backbone:\n    for param in layer.parameters():\n        param.requires_grad = True\n        \nSC_MODEL=train_and_val(SimCLR_ImagenetPT_model.backbone)\nSC_M_2=metrics(SC_MODEL)","metadata":{"execution":{"iopub.status.busy":"2023-11-26T12:24:28.640107Z","iopub.execute_input":"2023-11-26T12:24:28.640784Z","iopub.status.idle":"2023-11-26T13:37:15.818721Z","shell.execute_reply.started":"2023-11-26T12:24:28.640749Z","shell.execute_reply":"2023-11-26T13:37:15.817702Z"},"trusted":true},"execution_count":41,"outputs":[{"name":"stdout","text":"TRAINING MODEL 1\n--------------------------------------------------------------\nEpoch [1/8], Step [20/60], Loss: 0.1225\nEpoch [1/8], Step [40/60], Loss: 0.0545\nEpoch [1/8], Step [60/60], Loss: 0.0246\nEpoch [2/8], Step [20/60], Loss: 0.0071\nEpoch [2/8], Step [40/60], Loss: 0.0156\nEpoch [2/8], Step [60/60], Loss: 0.0084\nEpoch [3/8], Step [20/60], Loss: 0.0193\nEpoch [3/8], Step [40/60], Loss: 0.0365\nEpoch [3/8], Step [60/60], Loss: 0.0481\nEpoch [4/8], Step [20/60], Loss: 0.0709\nEpoch [4/8], Step [40/60], Loss: 0.0235\nEpoch [4/8], Step [60/60], Loss: 0.0212\nEpoch [5/8], Step [20/60], Loss: 0.0085\nEpoch [5/8], Step [40/60], Loss: 0.0406\nEpoch [5/8], Step [60/60], Loss: 0.0261\nEpoch [6/8], Step [20/60], Loss: 0.0172\nEpoch [6/8], Step [40/60], Loss: 0.0463\nEpoch [6/8], Step [60/60], Loss: 0.0843\nEpoch [7/8], Step [20/60], Loss: 0.0679\nEpoch [7/8], Step [40/60], Loss: 0.0030\nEpoch [7/8], Step [60/60], Loss: 0.0043\nEpoch [8/8], Step [20/60], Loss: 0.0033\nEpoch [8/8], Step [40/60], Loss: 0.0117\nEpoch [8/8], Step [60/60], Loss: 0.0640\nTRAINING MODEL 2\n--------------------------------------------------------------\nEpoch [1/8], Step [20/120], Loss: 0.9991\nEpoch [1/8], Step [40/120], Loss: 0.6947\nEpoch [1/8], Step [60/120], Loss: 0.8271\nEpoch [1/8], Step [80/120], Loss: 0.8832\nEpoch [1/8], Step [100/120], Loss: 0.7788\nEpoch [1/8], Step [120/120], Loss: 0.6880\nEpoch [2/8], Step [20/120], Loss: 0.4562\nEpoch [2/8], Step [40/120], Loss: 0.8170\nEpoch [2/8], Step [60/120], Loss: 0.8806\nEpoch [2/8], Step [80/120], Loss: 0.6345\nEpoch [2/8], Step [100/120], Loss: 0.6532\nEpoch [2/8], Step [120/120], Loss: 0.8024\nEpoch [3/8], Step [20/120], Loss: 0.3664\nEpoch [3/8], Step [40/120], Loss: 0.5511\nEpoch [3/8], Step [60/120], Loss: 0.2980\nEpoch [3/8], Step [80/120], Loss: 0.3846\nEpoch [3/8], Step [100/120], Loss: 0.2410\nEpoch [3/8], Step [120/120], Loss: 0.5540\nEpoch [4/8], Step [20/120], Loss: 0.2802\nEpoch [4/8], Step [40/120], Loss: 0.2198\nEpoch [4/8], Step [60/120], Loss: 0.1366\nEpoch [4/8], Step [80/120], Loss: 0.1379\nEpoch [4/8], Step [100/120], Loss: 0.4349\nEpoch [4/8], Step [120/120], Loss: 0.1025\nEpoch [5/8], Step [20/120], Loss: 0.0723\nEpoch [5/8], Step [40/120], Loss: 0.2873\nEpoch [5/8], Step [60/120], Loss: 0.2052\nEpoch [5/8], Step [80/120], Loss: 0.1473\nEpoch [5/8], Step [100/120], Loss: 0.0184\nEpoch [5/8], Step [120/120], Loss: 0.3438\nEpoch [6/8], Step [20/120], Loss: 0.0995\nEpoch [6/8], Step [40/120], Loss: 0.0406\nEpoch [6/8], Step [60/120], Loss: 0.0494\nEpoch [6/8], Step [80/120], Loss: 0.1774\nEpoch [6/8], Step [100/120], Loss: 0.0388\nEpoch [6/8], Step [120/120], Loss: 0.0436\nEpoch [7/8], Step [20/120], Loss: 0.0923\nEpoch [7/8], Step [40/120], Loss: 0.2299\nEpoch [7/8], Step [60/120], Loss: 0.1519\nEpoch [7/8], Step [80/120], Loss: 0.0775\nEpoch [7/8], Step [100/120], Loss: 0.0912\nEpoch [7/8], Step [120/120], Loss: 0.2689\nEpoch [8/8], Step [20/120], Loss: 0.0953\nEpoch [8/8], Step [40/120], Loss: 0.0126\nEpoch [8/8], Step [60/120], Loss: 0.0245\nEpoch [8/8], Step [80/120], Loss: 0.0395\nEpoch [8/8], Step [100/120], Loss: 0.0194\nEpoch [8/8], Step [120/120], Loss: 0.0151\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**TRAINING OVER THE BARLOW TWINS MODEL**","metadata":{}},{"cell_type":"code","source":"for layer in BT_ImagenetPT_model.backbone:\n    for param in layer.parameters():\n        param.requires_grad = True\n        \nBT_MODEL=train_and_val(BT_ImagenetPT_model.backbone)\nBT_M_2=metrics(BT_MODEL)","metadata":{"execution":{"iopub.status.busy":"2023-11-26T13:37:15.820986Z","iopub.execute_input":"2023-11-26T13:37:15.821626Z","iopub.status.idle":"2023-11-26T15:34:21.557173Z","shell.execute_reply.started":"2023-11-26T13:37:15.821586Z","shell.execute_reply":"2023-11-26T15:34:21.556106Z"},"trusted":true},"execution_count":42,"outputs":[{"name":"stdout","text":"TRAINING MODEL 1\n--------------------------------------------------------------\nEpoch [1/8], Step [20/60], Loss: 1.4211\nEpoch [1/8], Step [40/60], Loss: 0.9256\nEpoch [1/8], Step [60/60], Loss: 0.9737\nEpoch [2/8], Step [20/60], Loss: 0.8778\nEpoch [2/8], Step [40/60], Loss: 1.4601\nEpoch [2/8], Step [60/60], Loss: 1.0175\nEpoch [3/8], Step [20/60], Loss: 0.9819\nEpoch [3/8], Step [40/60], Loss: 1.0935\nEpoch [3/8], Step [60/60], Loss: 1.0122\nEpoch [4/8], Step [20/60], Loss: 1.4271\nEpoch [4/8], Step [40/60], Loss: 0.9651\nEpoch [4/8], Step [60/60], Loss: 1.0012\nEpoch [5/8], Step [20/60], Loss: 0.7726\nEpoch [5/8], Step [40/60], Loss: 0.9134\nEpoch [5/8], Step [60/60], Loss: 1.0771\nEpoch [6/8], Step [20/60], Loss: 0.9720\nEpoch [6/8], Step [40/60], Loss: 0.8076\nEpoch [6/8], Step [60/60], Loss: 1.1480\nEpoch [7/8], Step [20/60], Loss: 0.8793\nEpoch [7/8], Step [40/60], Loss: 1.0764\nEpoch [7/8], Step [60/60], Loss: 0.9758\nEpoch [8/8], Step [20/60], Loss: 1.0200\nEpoch [8/8], Step [40/60], Loss: 0.8133\nEpoch [8/8], Step [60/60], Loss: 0.9872\nTRAINING MODEL 2\n--------------------------------------------------------------\nEpoch [1/8], Step [20/120], Loss: 2.2446\nEpoch [1/8], Step [40/120], Loss: 1.1150\nEpoch [1/8], Step [60/120], Loss: 1.0944\nEpoch [1/8], Step [80/120], Loss: 1.3026\nEpoch [1/8], Step [100/120], Loss: 0.9784\nEpoch [1/8], Step [120/120], Loss: 0.7648\nEpoch [2/8], Step [20/120], Loss: 1.0253\nEpoch [2/8], Step [40/120], Loss: 1.2776\nEpoch [2/8], Step [60/120], Loss: 0.9066\nEpoch [2/8], Step [80/120], Loss: 0.9360\nEpoch [2/8], Step [100/120], Loss: 0.8934\nEpoch [2/8], Step [120/120], Loss: 0.9203\nEpoch [3/8], Step [20/120], Loss: 0.7579\nEpoch [3/8], Step [40/120], Loss: 1.0604\nEpoch [3/8], Step [60/120], Loss: 1.1544\nEpoch [3/8], Step [80/120], Loss: 1.0503\nEpoch [3/8], Step [100/120], Loss: 1.1605\nEpoch [3/8], Step [120/120], Loss: 0.9276\nEpoch [4/8], Step [20/120], Loss: 0.8609\nEpoch [4/8], Step [40/120], Loss: 1.0240\nEpoch [4/8], Step [60/120], Loss: 0.9456\nEpoch [4/8], Step [80/120], Loss: 0.8553\nEpoch [4/8], Step [100/120], Loss: 0.8244\nEpoch [4/8], Step [120/120], Loss: 1.0579\nEpoch [5/8], Step [20/120], Loss: 0.9426\nEpoch [5/8], Step [40/120], Loss: 1.0850\nEpoch [5/8], Step [60/120], Loss: 0.8469\nEpoch [5/8], Step [80/120], Loss: 0.8001\nEpoch [5/8], Step [100/120], Loss: 0.7242\nEpoch [5/8], Step [120/120], Loss: 0.9215\nEpoch [6/8], Step [20/120], Loss: 0.7596\nEpoch [6/8], Step [40/120], Loss: 1.0452\nEpoch [6/8], Step [60/120], Loss: 0.7896\nEpoch [6/8], Step [80/120], Loss: 1.0562\nEpoch [6/8], Step [100/120], Loss: 1.1063\nEpoch [6/8], Step [120/120], Loss: 0.9580\nEpoch [7/8], Step [20/120], Loss: 0.7487\nEpoch [7/8], Step [40/120], Loss: 0.7971\nEpoch [7/8], Step [60/120], Loss: 1.1325\nEpoch [7/8], Step [80/120], Loss: 0.9005\nEpoch [7/8], Step [100/120], Loss: 0.7080\nEpoch [7/8], Step [120/120], Loss: 0.8897\nEpoch [8/8], Step [20/120], Loss: 1.0071\nEpoch [8/8], Step [40/120], Loss: 0.8122\nEpoch [8/8], Step [60/120], Loss: 0.8722\nEpoch [8/8], Step [80/120], Loss: 0.8757\nEpoch [8/8], Step [100/120], Loss: 0.8629\nEpoch [8/8], Step [120/120], Loss: 0.7280\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**TRAINING OVER THE SWAV MODEL**","metadata":{}},{"cell_type":"code","source":"for layer in SW_ImagenetPT_model.backbone:\n    for param in layer.parameters():\n        param.requires_grad = True\n        \nSW_MODEL=train_and_val(SW_ImagenetPT_model.backbone)\nSW_M_2=metrics(SW_MODEL)","metadata":{"execution":{"iopub.status.busy":"2023-11-26T15:34:21.558938Z","iopub.execute_input":"2023-11-26T15:34:21.559658Z","iopub.status.idle":"2023-11-26T16:46:39.269482Z","shell.execute_reply.started":"2023-11-26T15:34:21.559615Z","shell.execute_reply":"2023-11-26T16:46:39.268248Z"},"trusted":true},"execution_count":43,"outputs":[{"name":"stdout","text":"TRAINING MODEL 1\n--------------------------------------------------------------\nEpoch [1/8], Step [20/60], Loss: 0.9821\nEpoch [1/8], Step [40/60], Loss: 0.8278\nEpoch [1/8], Step [60/60], Loss: 0.9444\nEpoch [2/8], Step [20/60], Loss: 0.8421\nEpoch [2/8], Step [40/60], Loss: 0.9567\nEpoch [2/8], Step [60/60], Loss: 0.8335\nEpoch [3/8], Step [20/60], Loss: 0.9686\nEpoch [3/8], Step [40/60], Loss: 0.9122\nEpoch [3/8], Step [60/60], Loss: 0.7970\nEpoch [4/8], Step [20/60], Loss: 0.7301\nEpoch [4/8], Step [40/60], Loss: 0.9920\nEpoch [4/8], Step [60/60], Loss: 0.8611\nEpoch [5/8], Step [20/60], Loss: 0.7934\nEpoch [5/8], Step [40/60], Loss: 0.8550\nEpoch [5/8], Step [60/60], Loss: 0.8397\nEpoch [6/8], Step [20/60], Loss: 0.9234\nEpoch [6/8], Step [40/60], Loss: 0.7627\nEpoch [6/8], Step [60/60], Loss: 0.8621\nEpoch [7/8], Step [20/60], Loss: 0.9211\nEpoch [7/8], Step [40/60], Loss: 0.7408\nEpoch [7/8], Step [60/60], Loss: 0.7387\nEpoch [8/8], Step [20/60], Loss: 0.6980\nEpoch [8/8], Step [40/60], Loss: 0.6541\nEpoch [8/8], Step [60/60], Loss: 0.5887\nTRAINING MODEL 2\n--------------------------------------------------------------\nEpoch [1/8], Step [20/120], Loss: 0.8634\nEpoch [1/8], Step [40/120], Loss: 0.6742\nEpoch [1/8], Step [60/120], Loss: 0.5980\nEpoch [1/8], Step [80/120], Loss: 0.7142\nEpoch [1/8], Step [100/120], Loss: 0.5752\nEpoch [1/8], Step [120/120], Loss: 0.5185\nEpoch [2/8], Step [20/120], Loss: 0.5938\nEpoch [2/8], Step [40/120], Loss: 0.5321\nEpoch [2/8], Step [60/120], Loss: 0.5905\nEpoch [2/8], Step [80/120], Loss: 0.4658\nEpoch [2/8], Step [100/120], Loss: 0.7118\nEpoch [2/8], Step [120/120], Loss: 0.6321\nEpoch [3/8], Step [20/120], Loss: 0.6055\nEpoch [3/8], Step [40/120], Loss: 0.4432\nEpoch [3/8], Step [60/120], Loss: 0.7386\nEpoch [3/8], Step [80/120], Loss: 0.5684\nEpoch [3/8], Step [100/120], Loss: 0.5669\nEpoch [3/8], Step [120/120], Loss: 0.5395\nEpoch [4/8], Step [20/120], Loss: 0.3817\nEpoch [4/8], Step [40/120], Loss: 0.3574\nEpoch [4/8], Step [60/120], Loss: 0.3863\nEpoch [4/8], Step [80/120], Loss: 0.3552\nEpoch [4/8], Step [100/120], Loss: 0.4797\nEpoch [4/8], Step [120/120], Loss: 0.7016\nEpoch [5/8], Step [20/120], Loss: 0.2993\nEpoch [5/8], Step [40/120], Loss: 0.4082\nEpoch [5/8], Step [60/120], Loss: 0.5035\nEpoch [5/8], Step [80/120], Loss: 0.6463\nEpoch [5/8], Step [100/120], Loss: 0.3144\nEpoch [5/8], Step [120/120], Loss: 0.3001\nEpoch [6/8], Step [20/120], Loss: 0.1691\nEpoch [6/8], Step [40/120], Loss: 0.3416\nEpoch [6/8], Step [60/120], Loss: 0.1276\nEpoch [6/8], Step [80/120], Loss: 0.2710\nEpoch [6/8], Step [100/120], Loss: 0.5238\nEpoch [6/8], Step [120/120], Loss: 0.3558\nEpoch [7/8], Step [20/120], Loss: 0.0444\nEpoch [7/8], Step [40/120], Loss: 0.4187\nEpoch [7/8], Step [60/120], Loss: 0.1916\nEpoch [7/8], Step [80/120], Loss: 0.1116\nEpoch [7/8], Step [100/120], Loss: 0.1714\nEpoch [7/8], Step [120/120], Loss: 0.1964\nEpoch [8/8], Step [20/120], Loss: 0.0996\nEpoch [8/8], Step [40/120], Loss: 0.1997\nEpoch [8/8], Step [60/120], Loss: 0.1136\nEpoch [8/8], Step [80/120], Loss: 0.2751\nEpoch [8/8], Step [100/120], Loss: 0.0969\nEpoch [8/8], Step [120/120], Loss: 0.2347\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**TRAINING OVER THE UNTRAINED RESNET MODEL**","metadata":{}},{"cell_type":"code","source":"resnet = torchvision.models.resnet18()\nuntrained= nn.Sequential(*list(resnet.children())[:-1])\n\nfor layer in untrained:\n    for param in layer.parameters():\n        param.requires_grad = True\n\nUN_MODEL=train_and_val(untrained)\nUN_M_2=metrics(UN_MODEL)","metadata":{"execution":{"iopub.status.busy":"2023-11-26T17:24:47.589095Z","iopub.execute_input":"2023-11-26T17:24:47.589435Z","iopub.status.idle":"2023-11-26T18:42:55.447175Z","shell.execute_reply.started":"2023-11-26T17:24:47.589408Z","shell.execute_reply":"2023-11-26T18:42:55.446186Z"},"trusted":true},"execution_count":46,"outputs":[{"name":"stdout","text":"TRAINING MODEL 1\n--------------------------------------------------------------\nEpoch [1/8], Step [20/60], Loss: 1.0261\nEpoch [1/8], Step [40/60], Loss: 0.8202\nEpoch [1/8], Step [60/60], Loss: 1.0495\nEpoch [2/8], Step [20/60], Loss: 0.9586\nEpoch [2/8], Step [40/60], Loss: 0.8829\nEpoch [2/8], Step [60/60], Loss: 0.7844\nEpoch [3/8], Step [20/60], Loss: 0.7956\nEpoch [3/8], Step [40/60], Loss: 0.7340\nEpoch [3/8], Step [60/60], Loss: 0.7972\nEpoch [4/8], Step [20/60], Loss: 0.8321\nEpoch [4/8], Step [40/60], Loss: 0.8198\nEpoch [4/8], Step [60/60], Loss: 0.7090\nEpoch [5/8], Step [20/60], Loss: 0.5279\nEpoch [5/8], Step [40/60], Loss: 0.8403\nEpoch [5/8], Step [60/60], Loss: 0.8385\nEpoch [6/8], Step [20/60], Loss: 0.4899\nEpoch [6/8], Step [40/60], Loss: 0.6946\nEpoch [6/8], Step [60/60], Loss: 0.3735\nEpoch [7/8], Step [20/60], Loss: 0.4955\nEpoch [7/8], Step [40/60], Loss: 0.3233\nEpoch [7/8], Step [60/60], Loss: 0.5450\nEpoch [8/8], Step [20/60], Loss: 0.3981\nEpoch [8/8], Step [40/60], Loss: 0.2697\nEpoch [8/8], Step [60/60], Loss: 0.3872\nTRAINING MODEL 2\n--------------------------------------------------------------\nEpoch [1/8], Step [20/120], Loss: 0.9956\nEpoch [1/8], Step [40/120], Loss: 0.6378\nEpoch [1/8], Step [60/120], Loss: 0.9519\nEpoch [1/8], Step [80/120], Loss: 0.8263\nEpoch [1/8], Step [100/120], Loss: 0.7594\nEpoch [1/8], Step [120/120], Loss: 0.6746\nEpoch [2/8], Step [20/120], Loss: 1.0021\nEpoch [2/8], Step [40/120], Loss: 0.4452\nEpoch [2/8], Step [60/120], Loss: 0.4634\nEpoch [2/8], Step [80/120], Loss: 0.4997\nEpoch [2/8], Step [100/120], Loss: 0.5218\nEpoch [2/8], Step [120/120], Loss: 0.3683\nEpoch [3/8], Step [20/120], Loss: 0.2406\nEpoch [3/8], Step [40/120], Loss: 0.2042\nEpoch [3/8], Step [60/120], Loss: 0.3672\nEpoch [3/8], Step [80/120], Loss: 0.3615\nEpoch [3/8], Step [100/120], Loss: 0.2563\nEpoch [3/8], Step [120/120], Loss: 0.5169\nEpoch [4/8], Step [20/120], Loss: 0.1641\nEpoch [4/8], Step [40/120], Loss: 0.1719\nEpoch [4/8], Step [60/120], Loss: 0.2369\nEpoch [4/8], Step [80/120], Loss: 0.2145\nEpoch [4/8], Step [100/120], Loss: 0.1404\nEpoch [4/8], Step [120/120], Loss: 0.2476\nEpoch [5/8], Step [20/120], Loss: 0.0890\nEpoch [5/8], Step [40/120], Loss: 0.1223\nEpoch [5/8], Step [60/120], Loss: 0.2352\nEpoch [5/8], Step [80/120], Loss: 0.1863\nEpoch [5/8], Step [100/120], Loss: 0.1356\nEpoch [5/8], Step [120/120], Loss: 0.2077\nEpoch [6/8], Step [20/120], Loss: 0.4097\nEpoch [6/8], Step [40/120], Loss: 0.1789\nEpoch [6/8], Step [60/120], Loss: 0.2149\nEpoch [6/8], Step [80/120], Loss: 0.0285\nEpoch [6/8], Step [100/120], Loss: 0.1238\nEpoch [6/8], Step [120/120], Loss: 0.1295\nEpoch [7/8], Step [20/120], Loss: 0.0194\nEpoch [7/8], Step [40/120], Loss: 0.0298\nEpoch [7/8], Step [100/120], Loss: 0.0393\nEpoch [7/8], Step [120/120], Loss: 0.1559\nEpoch [8/8], Step [20/120], Loss: 0.0674\nEpoch [8/8], Step [40/120], Loss: 0.1133\nEpoch [8/8], Step [60/120], Loss: 0.2196\nEpoch [8/8], Step [80/120], Loss: 0.0372\nEpoch [8/8], Step [100/120], Loss: 0.1173\nEpoch [8/8], Step [120/120], Loss: 0.0507\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"}]},{"cell_type":"code","source":"SC_M_2=metrics(SC_MODEL)\nBT_M_2=metrics(BT_MODEL)\nSW_M_2=metrics(SW_MODEL)\nUN_M_2=metrics(UN_MODEL)","metadata":{"execution":{"iopub.status.busy":"2023-11-26T18:58:23.452717Z","iopub.execute_input":"2023-11-26T18:58:23.453867Z","iopub.status.idle":"2023-11-26T19:02:29.716346Z","shell.execute_reply.started":"2023-11-26T18:58:23.453808Z","shell.execute_reply":"2023-11-26T19:02:29.715233Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"markdown","source":"**PRINTING THE METRICS**","metadata":{}},{"cell_type":"code","source":"print('SIMCLR',SC_M_2)\nprint('Barlow',BT_M_2)\nprint('Swav',SW_M_2)\nprint('Untrained',UN_M_2)","metadata":{"execution":{"iopub.status.busy":"2023-11-26T19:02:29.718326Z","iopub.execute_input":"2023-11-26T19:02:29.718912Z","iopub.status.idle":"2023-11-26T19:02:29.724415Z","shell.execute_reply.started":"2023-11-26T19:02:29.718877Z","shell.execute_reply":"2023-11-26T19:02:29.723294Z"},"trusted":true},"execution_count":58,"outputs":[{"name":"stdout","text":"SIMCLR 2.329001606654363\nBarlow 1.0083574661858525\nSwav 1.0502310608487553\nUntrained 1.1065804704628288\n","output_type":"stream"}]}]}
