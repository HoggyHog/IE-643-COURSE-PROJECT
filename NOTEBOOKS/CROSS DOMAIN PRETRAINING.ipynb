{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":861496,"sourceType":"datasetVersion","datasetId":457093},{"sourceId":2738526,"sourceType":"datasetVersion","datasetId":1669494},{"sourceId":7013184,"sourceType":"datasetVersion","datasetId":4032317},{"sourceId":7013189,"sourceType":"datasetVersion","datasetId":4032321},{"sourceId":7013197,"sourceType":"datasetVersion","datasetId":4032329}],"dockerImageVersionId":30588,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install lightly -q","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-11-29T16:00:38.757674Z","iopub.execute_input":"2023-11-29T16:00:38.757988Z","iopub.status.idle":"2023-11-29T16:00:55.842498Z","shell.execute_reply.started":"2023-11-29T16:00:38.757952Z","shell.execute_reply":"2023-11-29T16:00:55.841298Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"#dependencies for file management and data visualisation\nimport os\nimport shutil\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport nibabel as nib\nimport re\nfrom tqdm import tqdm\nimport pandas as pd\nimport gc\nimport psutil\nfrom matplotlib.animation import FuncAnimation\nimport seaborn as sns\nfrom IPython.display import HTML\nimport cv2\n\n#pretraining dependencies\nfrom lightly.data import LightlyDataset\n\n#pretraining of SIMCLR MODEL\nfrom lightly.transforms.simclr_transform import SimCLRTransform\nfrom lightly.loss import NTXentLoss\nfrom lightly.models.modules.heads import SimCLRProjectionHead\n\n#pretraining of BarlowTwins MODEL\nfrom lightly.loss import BarlowTwinsLoss\nfrom lightly.models.modules import BarlowTwinsProjectionHead\nfrom lightly.transforms.byol_transform import (\n    BYOLTransform,\n    BYOLView1Transform,\n    BYOLView2Transform,\n)\n\n#pretraining on SWaV MODEL\nfrom lightly.loss import SwaVLoss\nfrom lightly.models.modules import SwaVProjectionHead, SwaVPrototypes\nfrom lightly.transforms.swav_transform import SwaVTransform\n\n\n#fine-tuning the models\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n\nimport torch.optim as optim\nfrom torch.utils.data import TensorDataset, DataLoader , random_split\nimport pytorch_lightning as pl\nimport torchvision\nfrom torchvision import transforms\nfrom pytorch_lightning import seed_everything\n\n#evaluating the models\nfrom sklearn.metrics import log_loss\n\nseed_value = 50\n\ntorch.manual_seed(seed_value)\n\nif torch.cuda.is_available():\n    torch.cuda.manual_seed_all(seed_value)\n\nseed_everything(42)","metadata":{"execution":{"iopub.status.busy":"2023-11-29T16:00:55.845117Z","iopub.execute_input":"2023-11-29T16:00:55.845518Z","iopub.status.idle":"2023-11-29T16:01:04.404956Z","shell.execute_reply.started":"2023-11-29T16:00:55.845481Z","shell.execute_reply":"2023-11-29T16:01:04.404044Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"},{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"42"},"metadata":{}}]},{"cell_type":"code","source":"imagenet_path='/kaggle/input/tinyimagenet200/tiny-imagenet-200/train'\nfinal_loc1='/kaggle/natural'\nc=0\n\n#os.makedirs(final_loc, exist_ok=True)\nos.makedirs(final_loc1)\n\nfor directory in os.listdir(imagenet_path):\n    c+=1\n    directory_loc=os.path.join(imagenet_path,directory,'images')\n    for file in os.listdir(directory_loc):\n        \n        OLD_PATH=os.path.join(directory_loc,file)\n        NEW_PATH=os.path.join(final_loc1,file)\n        #os.replace(OLD_PATH,NEW_PATH)\n        #print(OLD_PATH, NEW_PATH)\n        \n        \n        shutil.copy(OLD_PATH, NEW_PATH)\n        \n   \n    if(c%20==0):\n        print(f'{c} DIRECTORIES TRANSFERED')\n\n","metadata":{"execution":{"iopub.status.busy":"2023-11-29T16:01:04.406388Z","iopub.execute_input":"2023-11-29T16:01:04.407290Z","iopub.status.idle":"2023-11-29T16:12:07.149662Z","shell.execute_reply.started":"2023-11-29T16:01:04.407250Z","shell.execute_reply":"2023-11-29T16:12:07.148729Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"20 DIRECTORIES TRANSFERED\n40 DIRECTORIES TRANSFERED\n60 DIRECTORIES TRANSFERED\n80 DIRECTORIES TRANSFERED\n100 DIRECTORIES TRANSFERED\n120 DIRECTORIES TRANSFERED\n140 DIRECTORIES TRANSFERED\n160 DIRECTORIES TRANSFERED\n180 DIRECTORIES TRANSFERED\n200 DIRECTORIES TRANSFERED\n","output_type":"stream"}]},{"cell_type":"code","source":"counter=0\nfor i in os.listdir(final_loc1):\n    counter+=1\nprint(c,counter)","metadata":{"execution":{"iopub.status.busy":"2023-11-29T16:12:07.152400Z","iopub.execute_input":"2023-11-29T16:12:07.152774Z","iopub.status.idle":"2023-11-29T16:12:07.230324Z","shell.execute_reply.started":"2023-11-29T16:12:07.152738Z","shell.execute_reply":"2023-11-29T16:12:07.229522Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"200 100000\n","output_type":"stream"}]},{"cell_type":"code","source":"final_loc2='/kaggle/mri'\nc=0","metadata":{"execution":{"iopub.status.busy":"2023-11-29T16:12:07.231723Z","iopub.execute_input":"2023-11-29T16:12:07.231992Z","iopub.status.idle":"2023-11-29T16:12:07.238265Z","shell.execute_reply.started":"2023-11-29T16:12:07.231969Z","shell.execute_reply":"2023-11-29T16:12:07.237333Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"mri1_no='/kaggle/input/brain-mri1/no'\nmri1_yes='/kaggle/input/brain-mri1/yes'\n\nos.makedirs(final_loc2,exist_ok=True)\nfor file in os.listdir(mri1_no):\n    c+=1\n    \n    file_path=os.path.join(mri1_no,file)\n    ext=file[-4:]\n    if(ext=='jpeg'):\n        ext='.jpeg'\n    new_filename=str(c)+ext\n    final_path=os.path.join(final_loc2,new_filename)\n    \n    shutil.copy(file_path, final_path)\n    \nfor file in os.listdir(mri1_yes):\n    c+=1\n    \n    file_path=os.path.join(mri1_yes,file)\n    ext=file[-4:]\n    if(ext=='jpeg'):\n        ext='.jpeg'\n    new_filename=str(c)+ext\n    final_path=os.path.join(final_loc2,new_filename)\n    \n    shutil.copy(file_path, final_path)\n    \n    ","metadata":{"execution":{"iopub.status.busy":"2023-11-29T16:12:07.239462Z","iopub.execute_input":"2023-11-29T16:12:07.240096Z","iopub.status.idle":"2023-11-29T16:12:09.112104Z","shell.execute_reply.started":"2023-11-29T16:12:07.240063Z","shell.execute_reply":"2023-11-29T16:12:09.111315Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"mri2_test='/kaggle/input/brain-mri2/Testing'\nmri2_train='/kaggle/input/brain-mri2/Training'\n\ntypes=['glioma_tumor','meningioma_tumor','no_tumor','pituitary_tumor']\n\nfor i in range(4):\n    folder_path=os.path.join(mri2_test,types[i])\n    for file in os.listdir(folder_path):\n        c+=1\n        file_path=os.path.join(folder_path,file)\n        new_filename=str(c)+'.jpg'\n        final_path=os.path.join(final_loc2,new_filename)\n        \n        shutil.copy(file_path, final_path)\n\nfor i in range(4):\n    folder_path=os.path.join(mri2_train,types[i])\n    for file in os.listdir(folder_path):\n        c+=1\n        file_path=os.path.join(folder_path,file)\n        new_filename=str(c)+'.jpg'\n        final_path=os.path.join(final_loc2,new_filename)\n        \n        shutil.copy(file_path, final_path)      ","metadata":{"execution":{"iopub.status.busy":"2023-11-29T16:12:09.113441Z","iopub.execute_input":"2023-11-29T16:12:09.113799Z","iopub.status.idle":"2023-11-29T16:12:32.635884Z","shell.execute_reply.started":"2023-11-29T16:12:09.113764Z","shell.execute_reply":"2023-11-29T16:12:32.635091Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"mri3_yes='/kaggle/input/brain-mri3/yes'\nmri3_no='/kaggle/input/brain-mri3/no'\n\nfor file in os.listdir(mri3_yes):\n    c+=1\n    file_path=os.path.join(mri3_yes,file)\n    new_filename=str(c)+'.jpg'\n    final_path=os.path.join(final_loc2,new_filename)\n    \n    shutil.copy(file_path,final_path)\n    \nfor file in os.listdir(mri3_no):\n    c+=1\n    file_path=os.path.join(mri3_no,file)\n    new_filename=str(c)+'.jpg'\n    final_path=os.path.join(final_loc2,new_filename)\n    \n    shutil.copy(file_path,final_path)","metadata":{"execution":{"iopub.status.busy":"2023-11-29T16:12:32.637136Z","iopub.execute_input":"2023-11-29T16:12:32.637581Z","iopub.status.idle":"2023-11-29T16:12:56.619474Z","shell.execute_reply.started":"2023-11-29T16:12:32.637541Z","shell.execute_reply":"2023-11-29T16:12:56.618514Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"counter=0\nfor i in os.listdir(final_loc2):\n    counter+=1\nprint(c,counter)","metadata":{"execution":{"iopub.status.busy":"2023-11-29T16:12:56.620777Z","iopub.execute_input":"2023-11-29T16:12:56.621504Z","iopub.status.idle":"2023-11-29T16:12:56.632339Z","shell.execute_reply.started":"2023-11-29T16:12:56.621469Z","shell.execute_reply":"2023-11-29T16:12:56.631403Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"6517 6517\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**PUTTING UP THE FIRST MODEL NOW**","metadata":{}},{"cell_type":"code","source":"max_epochs=40\n\nclass BarlowTwins(pl.LightningModule):\n    def __init__(self,backbone):\n        super().__init__()\n        resnet = torchvision.models.resnet18()\n        self.backbone = backbone\n        self.projection_head = BarlowTwinsProjectionHead(512, 2048, 2048)\n        self.criterion = BarlowTwinsLoss()\n\n    def forward(self, x):\n        x = self.backbone(x).flatten(start_dim=1)\n        z = self.projection_head(x)\n        return z\n\n    def training_step(self, batch, batch_index):\n        (x0, x1) = batch[0]\n        z0 = self.forward(x0)\n        z1 = self.forward(x1)\n        loss = self.criterion(z0, z1)\n        return loss\n\n    def configure_optimizers(self):\n        optim = torch.optim.SGD(self.parameters(), lr=0.06)\n        return optim","metadata":{"execution":{"iopub.status.busy":"2023-11-29T16:12:56.635516Z","iopub.execute_input":"2023-11-29T16:12:56.635819Z","iopub.status.idle":"2023-11-29T16:12:56.667924Z","shell.execute_reply.started":"2023-11-29T16:12:56.635795Z","shell.execute_reply":"2023-11-29T16:12:56.667155Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"BT_Imagenet_transform = BYOLTransform(\n    view_1_transform=BYOLView1Transform(input_size=32, gaussian_blur=0.0),\n    view_2_transform=BYOLView2Transform(input_size=32, gaussian_blur=0.0),\n)\n\nBT_Imagenet_dataset = LightlyDataset(\n    input_dir=final_loc1,\n    transform=BT_Imagenet_transform,\n)\n\nBT_Imagenet_dataloader = torch.utils.data.DataLoader(\n    BT_Imagenet_dataset,   \n    batch_size=16,         \n    shuffle=True,           \n    num_workers=4\n)\n        \n","metadata":{"execution":{"iopub.status.busy":"2023-11-29T16:12:56.669174Z","iopub.execute_input":"2023-11-29T16:12:56.669770Z","iopub.status.idle":"2023-11-29T16:12:57.181712Z","shell.execute_reply.started":"2023-11-29T16:12:56.669743Z","shell.execute_reply":"2023-11-29T16:12:57.180992Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"torch.cuda.empty_cache()\nresnet = torchvision.models.resnet18()\nBT_ImagenetPT_model = BarlowTwins(nn.Sequential(*list(resnet.children())[:-1]))\ntrainer = pl.Trainer(max_epochs=max_epochs, devices=1, accelerator=\"gpu\")\ntrainer.fit(BT_ImagenetPT_model, BT_Imagenet_dataloader)","metadata":{"execution":{"iopub.status.busy":"2023-11-29T16:12:57.182860Z","iopub.execute_input":"2023-11-29T16:12:57.183146Z","iopub.status.idle":"2023-11-29T18:13:24.017067Z","shell.execute_reply.started":"2023-11-29T16:12:57.183121Z","shell.execute_reply":"2023-11-29T18:13:24.016150Z"},"trusted":true},"execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/plain":"Training: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5529bdf5ab6549a2b28c3556033730cc"}},"metadata":{}}]},{"cell_type":"code","source":"BT_Imagenet_transform = BYOLTransform(\n    view_1_transform=BYOLView1Transform(input_size=32, gaussian_blur=0.0),\n    view_2_transform=BYOLView2Transform(input_size=32, gaussian_blur=0.0),\n)\n\nBT_Imagenet_dataset = LightlyDataset(\n    input_dir=final_loc2,\n    transform=BT_Imagenet_transform,\n)\n\nBT_Imagenet_dataloader = torch.utils.data.DataLoader(\n    BT_Imagenet_dataset,   \n    batch_size=16,         \n    shuffle=True,           \n    num_workers=4\n)","metadata":{"execution":{"iopub.status.busy":"2023-11-29T18:13:24.018654Z","iopub.execute_input":"2023-11-29T18:13:24.018971Z","iopub.status.idle":"2023-11-29T18:13:24.057227Z","shell.execute_reply.started":"2023-11-29T18:13:24.018940Z","shell.execute_reply":"2023-11-29T18:13:24.056400Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"torch.cuda.empty_cache()\n#resnet = torchvision.models.resnet18()\nBT_ImagenetPT_model2 = BarlowTwins(BT_ImagenetPT_model.backbone)\ntrainer = pl.Trainer(max_epochs=max_epochs, devices=1, accelerator=\"gpu\")\ntrainer.fit(BT_ImagenetPT_model2, BT_Imagenet_dataloader)","metadata":{"execution":{"iopub.status.busy":"2023-11-29T18:13:24.058325Z","iopub.execute_input":"2023-11-29T18:13:24.058608Z","iopub.status.idle":"2023-11-29T18:23:08.780242Z","shell.execute_reply.started":"2023-11-29T18:13:24.058584Z","shell.execute_reply":"2023-11-29T18:23:08.779207Z"},"trusted":true},"execution_count":14,"outputs":[{"output_type":"display_data","data":{"text/plain":"Training: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"daab439e54e44ef49b2ef38a3bd684ff"}},"metadata":{}}]},{"cell_type":"code","source":"def one_hot(n):\n    index={0:0,0.5:1,1:2,2:3}\n    #print(index)\n    #print(index[n])\n    y_new=np.zeros(4)\n    y_new[index[n]]=1\n    #print(y_new)\n    return y_new","metadata":{"execution":{"iopub.status.busy":"2023-11-29T18:23:08.782110Z","iopub.execute_input":"2023-11-29T18:23:08.782624Z","iopub.status.idle":"2023-11-29T18:23:08.789037Z","shell.execute_reply.started":"2023-11-29T18:23:08.782580Z","shell.execute_reply":"2023-11-29T18:23:08.788023Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"c=0\ndf_new = pd.DataFrame(columns=['IMG', 'CDR'])\ndef make_dataset(path,cdr):\n    \n    global c, df_new\n    \n    for i in os.listdir(path):\n        c+=1\n        image = cv2.imread(os.path.join(path,i))\n        image_np = np.array(image)\n        image_tensor = transforms.ToTensor()(image_np)\n        padded_image = transforms.CenterCrop((224, 224))(transforms.Pad(28)(image_tensor))\n        #print(padded_image.shape)\n        '''plt.imshow(padded_image.permute(1, 2, 0))\n        print('padded_image',padded_image.shape)'''  \n        \n        new_entry = {\n            'IMG': padded_image,\n            'CDR': cdr\n        } \n        df_new = pd.concat([df_new, pd.DataFrame([new_entry])], ignore_index=True)\n        #print(i)\n\n\nmake_dataset('/kaggle/input/alzheimers-dataset-4-class-of-images/Alzheimer_s Dataset/train/MildDemented',1)\nmake_dataset('/kaggle/input/alzheimers-dataset-4-class-of-images/Alzheimer_s Dataset/train/ModerateDemented',2)\nmake_dataset('/kaggle/input/alzheimers-dataset-4-class-of-images/Alzheimer_s Dataset/train/NonDemented',0)\nmake_dataset('/kaggle/input/alzheimers-dataset-4-class-of-images/Alzheimer_s Dataset/train/VeryMildDemented',0.5)\n        \nmake_dataset('/kaggle/input/alzheimers-dataset-4-class-of-images/Alzheimer_s Dataset/test/MildDemented',1)\nmake_dataset('/kaggle/input/alzheimers-dataset-4-class-of-images/Alzheimer_s Dataset/test/ModerateDemented',2)\nmake_dataset('/kaggle/input/alzheimers-dataset-4-class-of-images/Alzheimer_s Dataset/test/NonDemented',0)\nmake_dataset('/kaggle/input/alzheimers-dataset-4-class-of-images/Alzheimer_s Dataset/test/VeryMildDemented',0.5)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-29T18:23:08.790510Z","iopub.execute_input":"2023-11-29T18:23:08.790919Z","iopub.status.idle":"2023-11-29T18:23:56.309130Z","shell.execute_reply.started":"2023-11-29T18:23:08.790894Z","shell.execute_reply":"2023-11-29T18:23:56.308110Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"print(c,df_new.shape)\nprint(df_new['IMG'][0].shape)","metadata":{"execution":{"iopub.status.busy":"2023-11-29T18:23:56.310336Z","iopub.execute_input":"2023-11-29T18:23:56.310653Z","iopub.status.idle":"2023-11-29T18:23:56.319219Z","shell.execute_reply.started":"2023-11-29T18:23:56.310628Z","shell.execute_reply":"2023-11-29T18:23:56.318288Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"6400 (6400, 2)\ntorch.Size([3, 224, 224])\n","output_type":"stream"}]},{"cell_type":"code","source":"x=np.stack(df_new['IMG'].tolist())\ny=df_new['CDR']\n\ny_one_hot=[]\nfor i in y:\n    y_one_hot.append(one_hot(i)) ","metadata":{"execution":{"iopub.status.busy":"2023-11-29T18:23:56.320743Z","iopub.execute_input":"2023-11-29T18:23:56.321076Z","iopub.status.idle":"2023-11-29T18:23:57.537648Z","shell.execute_reply.started":"2023-11-29T18:23:56.321044Z","shell.execute_reply":"2023-11-29T18:23:57.536841Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"x=torch.tensor(x)\ny=torch.Tensor(y_one_hot)\n\ndataset=TensorDataset(x,y)\n\ntrain_size=int(0.8*len(x))\nval_size=int(0.1*len(x))\ntemp_size=2*val_size\n\n#print(train_size,val_size,temp_size)\n\ntrain_dataset, temp_dataset = random_split(dataset, [train_size, temp_size])\nval_dataset,test_dataset=random_split(temp_dataset, [val_size,val_size])\n\n# Define batch size\nbatch_size = 8\n\n# Create a DataLoader for shuffling and batching\ntrain_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\nval_dataloader = DataLoader(val_dataset, batch_size=1, shuffle=True)\ntest_dataloader=DataLoader(test_dataset,batch_size=1,shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2023-11-29T18:23:57.538898Z","iopub.execute_input":"2023-11-29T18:23:57.539538Z","iopub.status.idle":"2023-11-29T18:23:58.842520Z","shell.execute_reply.started":"2023-11-29T18:23:57.539502Z","shell.execute_reply":"2023-11-29T18:23:58.841610Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_47/79332094.py:2: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /usr/local/src/pytorch/torch/csrc/utils/tensor_new.cpp:245.)\n  y=torch.Tensor(y_one_hot)\n","output_type":"stream"}]},{"cell_type":"code","source":"def train_and_val(backbone):\n    \n    #training the models first on train_dataloader\n    \n    models=[]\n    for i in range(2):\n        models.append(ResnetSingleChannel(backbone,4))\n        \n   \n    \n    batch_sizes=[64,32]\n    \n    for model_no in range(2):\n        print(f'TRAINING MODEL {model_no+1}')\n        print('--------------------------------------------------------------')\n        fine_tune_opt = optim.Adam(models[model_no].parameters(), lr=0.001, weight_decay=0.0001)\n        ft_loss_fn= nn.CrossEntropyLoss()\n        \n        batch_size=batch_sizes[model_no]\n        \n        train_dataloader=DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n        val_dataloader = DataLoader(val_dataset, batch_size=1, shuffle=True)\n        \n\n        num_epochs = 10\n        total_steps=train_size//batch_size\n\n        for epoch in range(num_epochs):\n            i=0\n\n            for x_batch,y_batch in train_dataloader:\n                i+=1\n                outputs=models[model_no](torch.Tensor(x_batch))\n                \n                '''print('out',outputs.shape)\n                print('y',y_batch.shape)\n                print('out',outputs)\n                print('y',y_batch)'''\n                \n                loss = ft_loss_fn(outputs, y_batch)\n                fine_tune_opt.zero_grad()\n                loss.backward()\n                fine_tune_opt.step()\n\n                if (i+1) % 20 == 0:\n                    print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{total_steps}], Loss: {loss.item():.4f}')\n    \n    # performing validation on validation data_loader\n    best_model=-1\n    best_loss=np.inf\n    for model_no in range(2):\n        \n        loss_sum=0\n        \n        for x_batch,y_batch in val_dataloader:\n            outputs=models[model_no](torch.Tensor(x_batch))\n            loss = ft_loss_fn(outputs, y_batch)\n            loss_sum+=loss.item()\n            \n        if(loss_sum<best_loss):\n            best_model=model_no\n            best_loss=loss_sum\n    \n    return models[best_model]\n        \n        ","metadata":{"execution":{"iopub.status.busy":"2023-11-29T18:23:58.843952Z","iopub.execute_input":"2023-11-29T18:23:58.844582Z","iopub.status.idle":"2023-11-29T18:23:58.855822Z","shell.execute_reply.started":"2023-11-29T18:23:58.844545Z","shell.execute_reply":"2023-11-29T18:23:58.854969Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"def softmax(x):\n    return F.softmax(x,dim=-1)\n\ndef metrics(model):\n    \n    test_dataloader=DataLoader(test_dataset,batch_size=1,shuffle=True)\n    \n    y_pred_M=[]\n    y_true_M=[]\n    c=0\n    logloss_sum=0\n    \n    for x_batch,y_batch in test_dataloader:\n        \n        c+=1\n        y_pred=model(x_batch)\n\n        '''y_pred_M.append(np.argmax(y_pred.detach().numpy()))\n        y_true_M.append(np.argmax(y_batch.detach().numpy()))'''\n\n        softmax_probs = softmax(y_pred)\n\n        '''print(y_pred)\n        print(softmax_probs)\n        print(y_batch)'''\n\n        logloss = log_loss(y_batch.detach().numpy(), softmax_probs.detach().numpy())\n\n        logloss_sum+=logloss\n        #print(logloss) \n\n    return(logloss_sum/c)","metadata":{"execution":{"iopub.status.busy":"2023-11-29T18:23:58.856992Z","iopub.execute_input":"2023-11-29T18:23:58.857310Z","iopub.status.idle":"2023-11-29T18:23:58.869273Z","shell.execute_reply.started":"2023-11-29T18:23:58.857285Z","shell.execute_reply":"2023-11-29T18:23:58.868549Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"#MAKING A NEW NETWORK WHICH USES THE BACKBONE OF THE PRETRAINED MODEL, AND HAS AN INPUT LAYER TO TAKE IN A SINGLE CHANNEL IMAGE, AND THEN PASS INTO \n#BACKBONE, AND FINALLY OUTPUT LAYER WHICH PERFORMS REGRESSION\n\nclass ResnetSingleChannel(nn.Module):\n    def __init__(self,backbone,channels):\n        super(ResnetSingleChannel,self).__init__()\n        self.input=nn.Conv2d(3, 3, kernel_size=3, stride=1, padding=1, bias=False)\n        self.backbone=backbone\n        self.output=nn.Sequential(\n            nn.Flatten(),\n            nn.Linear(in_features=512, out_features=256),\n            nn.Linear(in_features=256, out_features=channels)\n        )\n        \n    def forward(self,x):\n        x=self.input(x)\n        x=self.backbone(x)\n        x=self.output(x)\n        \n        return x","metadata":{"execution":{"iopub.status.busy":"2023-11-29T18:23:58.870387Z","iopub.execute_input":"2023-11-29T18:23:58.870711Z","iopub.status.idle":"2023-11-29T18:23:58.880230Z","shell.execute_reply.started":"2023-11-29T18:23:58.870687Z","shell.execute_reply":"2023-11-29T18:23:58.879396Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"for layer in BT_ImagenetPT_model.backbone:\n    for param in layer.parameters():\n        param.requires_grad = True\n        \nBT_MODEL_final=train_and_val(BT_ImagenetPT_model2.backbone)\nBT_M_2=metrics(BT_MODEL_final)","metadata":{"execution":{"iopub.status.busy":"2023-11-29T18:23:58.881495Z","iopub.execute_input":"2023-11-29T18:23:58.881825Z","iopub.status.idle":"2023-11-30T02:12:22.054023Z","shell.execute_reply.started":"2023-11-29T18:23:58.881794Z","shell.execute_reply":"2023-11-30T02:12:22.052981Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"TRAINING MODEL 1\n--------------------------------------------------------------\nEpoch [1/10], Step [20/80], Loss: 6.5703\nEpoch [1/10], Step [40/80], Loss: 4.9681\nEpoch [1/10], Step [60/80], Loss: 3.8694\nEpoch [1/10], Step [80/80], Loss: 2.2077\nEpoch [2/10], Step [20/80], Loss: 2.2728\nEpoch [2/10], Step [40/80], Loss: 2.1596\nEpoch [2/10], Step [60/80], Loss: 1.9772\nEpoch [2/10], Step [80/80], Loss: 1.5075\nEpoch [3/10], Step [20/80], Loss: 1.1825\nEpoch [3/10], Step [40/80], Loss: 2.1609\nEpoch [3/10], Step [60/80], Loss: 1.1725\nEpoch [3/10], Step [80/80], Loss: 0.9854\nEpoch [4/10], Step [20/80], Loss: 0.8533\nEpoch [4/10], Step [40/80], Loss: 0.8921\nEpoch [4/10], Step [60/80], Loss: 0.9886\nEpoch [4/10], Step [80/80], Loss: 0.9208\nEpoch [5/10], Step [20/80], Loss: 1.6053\nEpoch [5/10], Step [40/80], Loss: 1.3355\nEpoch [5/10], Step [60/80], Loss: 1.7651\nEpoch [5/10], Step [80/80], Loss: 2.4242\nEpoch [6/10], Step [20/80], Loss: 1.0503\nEpoch [6/10], Step [40/80], Loss: 0.7691\nEpoch [6/10], Step [60/80], Loss: 1.3728\nEpoch [6/10], Step [80/80], Loss: 0.9764\nEpoch [7/10], Step [20/80], Loss: 0.9551\nEpoch [7/10], Step [40/80], Loss: 0.9933\nEpoch [7/10], Step [60/80], Loss: 1.0089\nEpoch [7/10], Step [80/80], Loss: 0.8577\nEpoch [8/10], Step [20/80], Loss: 0.9119\nEpoch [8/10], Step [40/80], Loss: 1.0071\nEpoch [8/10], Step [60/80], Loss: 0.8411\nEpoch [8/10], Step [80/80], Loss: 0.9585\nEpoch [9/10], Step [20/80], Loss: 1.1916\nEpoch [9/10], Step [40/80], Loss: 0.9743\nEpoch [9/10], Step [60/80], Loss: 0.9797\nEpoch [9/10], Step [80/80], Loss: 1.1341\nEpoch [10/10], Step [20/80], Loss: 0.9251\nEpoch [10/10], Step [40/80], Loss: 0.9085\nEpoch [10/10], Step [60/80], Loss: 0.9467\nEpoch [10/10], Step [80/80], Loss: 0.9857\nTRAINING MODEL 2\n--------------------------------------------------------------\nEpoch [1/10], Step [20/160], Loss: 4.9053\nEpoch [1/10], Step [40/160], Loss: 0.9636\nEpoch [1/10], Step [60/160], Loss: 3.2088\nEpoch [1/10], Step [80/160], Loss: 2.5637\nEpoch [1/10], Step [100/160], Loss: 3.5457\nEpoch [1/10], Step [120/160], Loss: 1.0148\nEpoch [1/10], Step [140/160], Loss: 4.6044\nEpoch [1/10], Step [160/160], Loss: 1.6448\nEpoch [2/10], Step [20/160], Loss: 1.2665\nEpoch [2/10], Step [40/160], Loss: 2.3794\nEpoch [2/10], Step [60/160], Loss: 1.6879\nEpoch [2/10], Step [80/160], Loss: 1.7961\nEpoch [2/10], Step [100/160], Loss: 1.4968\nEpoch [2/10], Step [120/160], Loss: 1.1132\nEpoch [2/10], Step [140/160], Loss: 1.0934\nEpoch [2/10], Step [160/160], Loss: 1.0210\nEpoch [3/10], Step [20/160], Loss: 1.2427\nEpoch [3/10], Step [40/160], Loss: 0.9393\nEpoch [3/10], Step [60/160], Loss: 2.1054\nEpoch [3/10], Step [80/160], Loss: 1.2301\nEpoch [3/10], Step [100/160], Loss: 0.9151\nEpoch [3/10], Step [120/160], Loss: 1.3544\nEpoch [3/10], Step [140/160], Loss: 0.9592\nEpoch [3/10], Step [160/160], Loss: 1.0449\nEpoch [4/10], Step [20/160], Loss: 1.1881\nEpoch [4/10], Step [40/160], Loss: 1.4262\nEpoch [4/10], Step [60/160], Loss: 1.0627\nEpoch [4/10], Step [80/160], Loss: 0.8892\nEpoch [4/10], Step [100/160], Loss: 0.8279\nEpoch [4/10], Step [120/160], Loss: 0.7537\nEpoch [4/10], Step [140/160], Loss: 0.8759\nEpoch [4/10], Step [160/160], Loss: 1.6746\nEpoch [5/10], Step [20/160], Loss: 1.0069\nEpoch [5/10], Step [40/160], Loss: 1.0003\nEpoch [5/10], Step [60/160], Loss: 1.1509\nEpoch [5/10], Step [80/160], Loss: 1.1275\nEpoch [5/10], Step [100/160], Loss: 2.2697\nEpoch [5/10], Step [120/160], Loss: 0.9399\nEpoch [5/10], Step [140/160], Loss: 1.0673\nEpoch [5/10], Step [160/160], Loss: 1.2042\nEpoch [6/10], Step [20/160], Loss: 0.8507\nEpoch [6/10], Step [40/160], Loss: 0.8678\nEpoch [6/10], Step [60/160], Loss: 1.0490\nEpoch [6/10], Step [80/160], Loss: 0.9258\nEpoch [6/10], Step [100/160], Loss: 0.7137\nEpoch [6/10], Step [120/160], Loss: 1.3193\nEpoch [6/10], Step [140/160], Loss: 1.0276\nEpoch [6/10], Step [160/160], Loss: 0.9374\nEpoch [7/10], Step [20/160], Loss: 1.1162\nEpoch [7/10], Step [40/160], Loss: 0.9441\nEpoch [7/10], Step [60/160], Loss: 1.3586\nEpoch [7/10], Step [80/160], Loss: 0.9922\nEpoch [7/10], Step [100/160], Loss: 1.0462\nEpoch [7/10], Step [120/160], Loss: 0.8435\nEpoch [7/10], Step [140/160], Loss: 0.9243\nEpoch [7/10], Step [160/160], Loss: 0.8762\nEpoch [8/10], Step [20/160], Loss: 0.8618\nEpoch [8/10], Step [40/160], Loss: 1.2310\nEpoch [8/10], Step [60/160], Loss: 0.7225\nEpoch [8/10], Step [80/160], Loss: 0.8988\nEpoch [8/10], Step [100/160], Loss: 2.0461\nEpoch [8/10], Step [120/160], Loss: 1.3103\nEpoch [8/10], Step [140/160], Loss: 0.7868\nEpoch [8/10], Step [160/160], Loss: 1.4358\nEpoch [9/10], Step [20/160], Loss: 1.0405\nEpoch [9/10], Step [40/160], Loss: 0.9104\nEpoch [9/10], Step [60/160], Loss: 1.0535\nEpoch [9/10], Step [80/160], Loss: 0.8749\nEpoch [9/10], Step [100/160], Loss: 1.1941\nEpoch [9/10], Step [120/160], Loss: 0.9904\nEpoch [9/10], Step [140/160], Loss: 1.0798\nEpoch [9/10], Step [160/160], Loss: 0.8659\nEpoch [10/10], Step [20/160], Loss: 0.8958\nEpoch [10/10], Step [40/160], Loss: 0.8825\nEpoch [10/10], Step [60/160], Loss: 0.9089\nEpoch [10/10], Step [80/160], Loss: 0.9620\nEpoch [10/10], Step [100/160], Loss: 0.9079\nEpoch [10/10], Step [120/160], Loss: 1.0270\nEpoch [10/10], Step [140/160], Loss: 0.8451\nEpoch [10/10], Step [160/160], Loss: 0.9502\n","output_type":"stream"}]},{"cell_type":"code","source":"print(BT_M_2)","metadata":{"execution":{"iopub.status.busy":"2023-11-30T02:12:22.055419Z","iopub.execute_input":"2023-11-30T02:12:22.055718Z","iopub.status.idle":"2023-11-30T02:12:22.061100Z","shell.execute_reply.started":"2023-11-30T02:12:22.055694Z","shell.execute_reply":"2023-11-30T02:12:22.060171Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"1.0218779558013367\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}
